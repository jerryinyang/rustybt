# Story 1.6: Implement Additional Performance Metrics

## Status
Draft

## Story
**As a** quantitative trader,
**I want** advanced performance metrics (Sortino, Calmar, CVaR, VaR, win rate, profit factor),
**so that** I can comprehensively evaluate strategy risk-adjusted returns and robustness.

## Acceptance Criteria
1. Sortino ratio calculated using downside deviation instead of total volatility
2. Calmar ratio calculated as annualized return / maximum drawdown
3. CVaR (Conditional Value at Risk) calculated at 95% and 99% confidence levels
4. VaR (Value at Risk) calculated at 95% and 99% confidence levels
5. Win rate calculated as percentage of profitable trades
6. Profit factor calculated as gross profits / gross losses
7. All metrics integrate into existing PerformanceTracker without breaking existing metrics
8. Performance summary report includes all new metrics alongside existing ones (Sharpe, max drawdown, returns)
9. Property-based tests validate metric calculations using Hypothesis with synthetic data
10. Documentation explains each metric with interpretation guidance

## Tasks / Subtasks
- [ ] Implement Sortino Ratio (AC: 1)
  - [ ] Calculate downside deviation (volatility of negative returns only)
  - [ ] Use risk-free rate or minimum acceptable return (MAR)
  - [ ] Formula: (Return - MAR) / Downside Deviation
  - [ ] Annualize result based on data frequency
  - [ ] Use Decimal arithmetic for precision
  - [ ] Add unit tests with known datasets

- [ ] Implement Calmar Ratio (AC: 2)
  - [ ] Calculate annualized return from cumulative returns
  - [ ] Get maximum drawdown from existing PerformanceTracker
  - [ ] Formula: Annualized Return / Maximum Drawdown
  - [ ] Handle edge case: zero or positive-only returns (infinite Calmar)
  - [ ] Use Decimal arithmetic
  - [ ] Add unit tests with known datasets

- [ ] Implement CVaR (Conditional Value at Risk) (AC: 3)
  - [ ] Calculate VaR at 95% and 99% confidence levels first
  - [ ] CVaR = mean of returns below VaR threshold
  - [ ] Also known as Expected Shortfall (ES)
  - [ ] Support both historical and parametric methods
  - [ ] Use Decimal for all calculations
  - [ ] Add unit tests with synthetic loss distributions

- [ ] Implement VaR (Value at Risk) (AC: 4)
  - [ ] Calculate VaR using historical method (percentile of return distribution)
  - [ ] Support 95% and 99% confidence levels
  - [ ] Optional: Parametric VaR using normal distribution assumption
  - [ ] Return as positive value (loss magnitude)
  - [ ] Use Decimal arithmetic
  - [ ] Add unit tests with known distributions

- [ ] Implement Win Rate (AC: 5)
  - [ ] Count profitable trades (P&L > 0)
  - [ ] Count total closed trades
  - [ ] Formula: Profitable Trades / Total Trades
  - [ ] Return as percentage (0-100)
  - [ ] Handle edge case: zero trades (return None or 0)
  - [ ] Use Decimal arithmetic
  - [ ] Add unit tests with known trade sequences

- [ ] Implement Profit Factor (AC: 6)
  - [ ] Sum gross profits (sum of all winning trades)
  - [ ] Sum gross losses (absolute value of sum of all losing trades)
  - [ ] Formula: Gross Profits / Gross Losses
  - [ ] Handle edge case: zero losses (infinite profit factor)
  - [ ] Use Decimal arithmetic
  - [ ] Add unit tests with known trade sequences

- [ ] Integrate with PerformanceTracker (AC: 7, 8)
  - [ ] Extend PerformanceTracker class in rustybt/finance/metrics/tracker.py
  - [ ] Add new metrics to performance summary dictionary
  - [ ] Ensure backward compatibility with existing metrics
  - [ ] Update cumulative performance DataFrame with new columns
  - [ ] Add new metrics to performance report output
  - [ ] Test integration with existing backtest workflow

- [ ] Update performance summary report (AC: 8)
  - [ ] Add new metrics to summary dictionary
  - [ ] Maintain existing metric names and structure
  - [ ] Format new metrics for readability (percentage, ratio, currency)
  - [ ] Add section headers for risk metrics vs. return metrics
  - [ ] Ensure report still prints correctly with new fields
  - [ ] Test report generation with backtest results

- [ ] Write comprehensive tests (AC: 9)
  - [ ] Unit tests for Sortino ratio with known datasets
  - [ ] Unit tests for Calmar ratio with known datasets
  - [ ] Unit tests for CVaR/VaR with synthetic distributions
  - [ ] Unit tests for win rate with known trade sequences
  - [ ] Unit tests for profit factor with known trade sequences
  - [ ] Integration test: Run backtest and verify all metrics calculated
  - [ ] Property-based tests using Hypothesis for edge cases

- [ ] Create documentation (AC: 10)
  - [ ] Document each metric in docs/metrics/performance-metrics.md
  - [ ] Explain calculation methodology
  - [ ] Provide interpretation guidance (what is "good" value)
  - [ ] Add example calculations with sample data
  - [ ] Create API reference for metrics functions
  - [ ] Add docstrings to all metric functions

## Dev Notes

### Existing Project Analysis
[Source: architecture/existing-project-analysis.md]

**Zipline Performance Tracking:**
- PerformanceTracker: `zipline/finance/performance/tracker.py`
- empyrical-reloaded: External library for metric calculations
- Existing metrics: Sharpe ratio, max drawdown, total return, volatility
- Metrics calculated on portfolio returns series

**Extension Strategy:**
- Extend PerformanceTracker with new metric methods
- Use empyrical-reloaded where possible, custom implementations where needed
- Maintain Decimal precision for financial calculations
- Integrate with existing performance reporting

### Component Architecture
[Source: architecture/component-architecture.md]

**Files to Extend:**
- `rustybt/finance/metrics/core.py`: Implement metric calculation functions
- `rustybt/finance/metrics/tracker.py`: Integrate metrics into PerformanceTracker
- `rustybt/finance/performance/tracker.py`: Main performance tracker (if separate)

**Metric Functions Structure:**
```python
from decimal import Decimal
import polars as pl
from typing import Optional

def sortino_ratio(
    returns: pl.Series,
    mar: Decimal = Decimal("0"),
    periods: int = 252
) -> Decimal:
    """Calculate Sortino ratio.

    Args:
        returns: Return series
        mar: Minimum acceptable return (default 0)
        periods: Periods per year for annualization

    Returns:
        Sortino ratio as Decimal
    """
    # Implementation
    pass

def calmar_ratio(
    returns: pl.Series,
    max_drawdown: Decimal
) -> Decimal:
    """Calculate Calmar ratio.

    Args:
        returns: Return series
        max_drawdown: Maximum drawdown (as positive value)

    Returns:
        Calmar ratio as Decimal
    """
    pass

def cvar(
    returns: pl.Series,
    confidence_level: Decimal = Decimal("0.95")
) -> Decimal:
    """Calculate Conditional Value at Risk (CVaR).

    Args:
        returns: Return series
        confidence_level: Confidence level (0.95 or 0.99)

    Returns:
        CVaR as Decimal (positive value = loss magnitude)
    """
    pass

def var(
    returns: pl.Series,
    confidence_level: Decimal = Decimal("0.95")
) -> Decimal:
    """Calculate Value at Risk (VaR).

    Args:
        returns: Return series
        confidence_level: Confidence level (0.95 or 0.99)

    Returns:
        VaR as Decimal (positive value = loss magnitude)
    """
    pass

def win_rate(
    transactions: pl.DataFrame
) -> Decimal:
    """Calculate win rate from transactions.

    Args:
        transactions: Transaction DataFrame with 'pnl' column

    Returns:
        Win rate as percentage (0-100)
    """
    pass

def profit_factor(
    transactions: pl.DataFrame
) -> Decimal:
    """Calculate profit factor from transactions.

    Args:
        transactions: Transaction DataFrame with 'pnl' column

    Returns:
        Profit factor as Decimal (gross profits / gross losses)
    """
    pass
```

### Tech Stack
[Source: architecture/tech-stack.md]

**Existing Libraries:**
- empyrical-reloaded: ≥0.5.7 (performance metrics)
- scipy: ≥0.17.1 (statistical functions)
- statsmodels: ≥0.6.1 (statistical models)

**New Dependencies:**
- Polars: For fast calculations on returns series
- Decimal: For financial precision

**Implementation Notes:**
- Prefer empyrical-reloaded for standard metrics (Sharpe, Sortino if available)
- Custom implementations for metrics not in empyrical
- Convert Polars to pandas if needed for empyrical compatibility

### Coding Standards
[Source: architecture/coding-standards.md]

**Type Hints:**
```python
from decimal import Decimal
import polars as pl
from typing import Optional, Tuple

def calculate_downside_deviation(
    returns: pl.Series,
    mar: Decimal = Decimal("0")
) -> Decimal:
    """Calculate downside deviation."""
    pass
```

**Docstrings:**
```python
def sortino_ratio(
    returns: pl.Series,
    mar: Decimal = Decimal("0"),
    periods: int = 252
) -> Decimal:
    """Calculate Sortino ratio using downside deviation.

    The Sortino ratio measures risk-adjusted return using downside deviation
    instead of total volatility, focusing on harmful volatility.

    Args:
        returns: Daily return series as Polars Series
        mar: Minimum acceptable return (default 0 for excess returns)
        periods: Number of periods per year (252 for daily, 12 for monthly)

    Returns:
        Sortino ratio as Decimal

    Example:
        >>> returns = pl.Series([0.01, -0.02, 0.03, -0.01, 0.02])
        >>> sortino = sortino_ratio(returns, periods=252)
        >>> print(f"Sortino Ratio: {sortino:.2f}")
        Sortino Ratio: 1.45

    Interpretation:
        - Higher is better (more return per unit of downside risk)
        - >2.0: Excellent
        - 1.0-2.0: Good
        - <1.0: Poor
    """
```

**Decimal Precision:**
```python
from decimal import Decimal, getcontext

# Set precision for metric calculations
getcontext().prec = 28

# Calculate downside deviation
downside_returns = returns.filter(returns < mar)
downside_dev = downside_returns.std() * Decimal(str(periods ** 0.5))
```

### Zero-Mock Enforcement
[Source: architecture/coding-standards.md#zero-mock-enforcement-mandatory]

**Real Implementations Required:**
- Sortino must calculate actual downside deviation (not hardcoded)
- CVaR must compute mean of tail losses (not fake percentile)
- Win rate must count actual profitable trades (not hardcoded percentage)
- Profit factor must sum real profits and losses (not mock values)

**Forbidden Patterns:**
```python
# ❌ FORBIDDEN
def sortino_ratio(returns):
    return Decimal("1.5")  # Mock value

def win_rate(transactions):
    return Decimal("60.0")  # Always 60%

# ✅ CORRECT
def sortino_ratio(
    returns: pl.Series,
    mar: Decimal = Decimal("0"),
    periods: int = 252
) -> Decimal:
    """Calculate actual Sortino ratio."""
    if len(returns) < 2:
        return Decimal("0")

    excess_returns = returns - float(mar)
    mean_return = Decimal(str(excess_returns.mean()))

    # Downside deviation: std of negative excess returns
    downside_returns = excess_returns.filter(excess_returns < 0)
    if len(downside_returns) == 0:
        return Decimal("Inf")  # No downside risk

    downside_std = Decimal(str(downside_returns.std()))
    annualized_downside = downside_std * Decimal(str(periods ** 0.5))

    if annualized_downside == 0:
        return Decimal("Inf")

    annualized_return = mean_return * Decimal(str(periods))
    return annualized_return / annualized_downside

def win_rate(transactions: pl.DataFrame) -> Decimal:
    """Calculate actual win rate from transactions."""
    if len(transactions) == 0:
        return Decimal("0")

    profitable = transactions.filter(pl.col('pnl') > 0)
    win_count = len(profitable)
    total_count = len(transactions)

    return (Decimal(win_count) / Decimal(total_count)) * Decimal("100")
```

### Testing Strategy
[Source: architecture/testing-strategy.md]

**Unit Tests:**
```python
def test_sortino_ratio_known_dataset():
    """Test Sortino ratio with known result."""
    returns = pl.Series([0.01, -0.02, 0.03, -0.01, 0.02, 0.01, -0.03, 0.04])
    sortino = sortino_ratio(returns, mar=Decimal("0"), periods=252)

    # Expected value calculated manually or with reference implementation
    expected = Decimal("1.234")  # Example expected value
    assert abs(sortino - expected) < Decimal("0.01")

def test_calmar_ratio_calculation():
    """Test Calmar ratio calculation."""
    returns = pl.Series([0.10, 0.05, -0.15, 0.08, 0.12])  # 20% total return
    max_dd = Decimal("0.15")  # 15% max drawdown

    calmar = calmar_ratio(returns, max_dd)

    # Annualized return / max drawdown
    # With 5 periods, annualized ~252/5 * 0.20 / 0.15
    assert calmar > Decimal("0")

def test_cvar_calculation():
    """Test CVaR calculation."""
    # Generate returns with known tail
    returns = pl.Series([-0.05, -0.03, -0.02, -0.01, 0.00, 0.01, 0.02, 0.03, 0.04, 0.05] * 10)

    cvar_95 = cvar(returns, confidence_level=Decimal("0.95"))
    cvar_99 = cvar(returns, confidence_level=Decimal("0.99"))

    # CVaR should be positive (loss magnitude)
    assert cvar_95 > Decimal("0")
    assert cvar_99 > Decimal("0")

    # CVaR99 should be worse (larger loss) than CVaR95
    assert cvar_99 >= cvar_95

def test_win_rate_calculation():
    """Test win rate from transactions."""
    transactions = pl.DataFrame({
        'pnl': [100.0, -50.0, 75.0, -25.0, 150.0, 200.0, -100.0]  # 4 wins, 3 losses
    })

    wr = win_rate(transactions)
    expected = Decimal("57.14")  # 4/7 = 57.14%

    assert abs(wr - expected) < Decimal("0.1")

def test_profit_factor_calculation():
    """Test profit factor from transactions."""
    transactions = pl.DataFrame({
        'pnl': [100.0, -50.0, 75.0, -25.0, 150.0]  # Profits: 325, Losses: 75
    })

    pf = profit_factor(transactions)
    expected = Decimal("325") / Decimal("75")  # 4.33

    assert abs(pf - expected) < Decimal("0.01")

def test_profit_factor_no_losses():
    """Test profit factor with no losses (infinite)."""
    transactions = pl.DataFrame({
        'pnl': [100.0, 75.0, 150.0]  # All winning
    })

    pf = profit_factor(transactions)
    assert pf == Decimal("Inf") or pf > Decimal("1000")  # Very high
```

**Property-Based Tests:**
```python
from hypothesis import given, strategies as st

@given(
    returns=st.lists(
        st.decimals(min_value=Decimal("-0.10"), max_value=Decimal("0.10")),
        min_size=30,
        max_size=1000
    )
)
def test_sortino_ratio_positive_returns(returns):
    """Sortino ratio should be positive for mostly positive returns."""
    returns_series = pl.Series([float(r) for r in returns])

    if returns_series.mean() > 0:
        sortino = sortino_ratio(returns_series)
        assert sortino > Decimal("0")

@given(
    returns=st.lists(
        st.decimals(min_value=Decimal("-0.20"), max_value=Decimal("0.20")),
        min_size=100,
        max_size=1000
    )
)
def test_cvar_worse_than_var(returns):
    """CVaR should always be >= VaR (worse loss)."""
    returns_series = pl.Series([float(r) for r in returns])

    var_95 = var(returns_series, Decimal("0.95"))
    cvar_95 = cvar(returns_series, Decimal("0.95"))

    assert cvar_95 >= var_95

@given(
    profits=st.lists(st.decimals(min_value=Decimal("1"), max_value=Decimal("1000")), min_size=1),
    losses=st.lists(st.decimals(min_value=Decimal("-1000"), max_value=Decimal("-1")), min_size=1)
)
def test_profit_factor_bounds(profits, losses):
    """Profit factor should be positive and reasonable."""
    pnl_list = profits + losses
    transactions = pl.DataFrame({'pnl': [float(p) for p in pnl_list]})

    pf = profit_factor(transactions)

    assert pf > Decimal("0")  # Always positive
    # If more profits than losses, PF > 1
    if sum(profits) > abs(sum(losses)):
        assert pf > Decimal("1")
```

**Integration Tests:**
```python
@pytest.mark.integration
def test_backtest_with_all_metrics():
    """Test backtest generates all performance metrics."""
    class SampleStrategy(TradingAlgorithm):
        def initialize(self, context):
            context.asset = self.symbol('AAPL')

        def handle_data(self, context, data):
            self.order(context.asset, 100)

    result = run_algorithm(
        algorithm=SampleStrategy(),
        start='2023-01-01',
        end='2023-12-31',
        data_frequency='daily'
    )

    # Verify all metrics present in performance summary
    perf = result.performance_summary

    assert 'sortino_ratio' in perf
    assert 'calmar_ratio' in perf
    assert 'cvar_95' in perf
    assert 'cvar_99' in perf
    assert 'var_95' in perf
    assert 'var_99' in perf
    assert 'win_rate' in perf
    assert 'profit_factor' in perf

    # Verify metrics are reasonable
    assert isinstance(perf['sortino_ratio'], Decimal)
    assert isinstance(perf['win_rate'], Decimal)
    assert Decimal("0") <= perf['win_rate'] <= Decimal("100")
```

**Test Coverage Target:**
- Unit tests: ≥95% coverage for metrics calculation
- Property tests: 1000+ examples for each metric
- Integration tests: Test all metrics in backtest workflow

### Metric Interpretation Guide

**Sortino Ratio:**
- Measures risk-adjusted return using downside volatility
- Higher is better
- >2.0: Excellent
- 1.0-2.0: Good
- <1.0: Poor

**Calmar Ratio:**
- Return per unit of maximum drawdown
- Higher is better
- >3.0: Excellent
- 1.0-3.0: Good
- <1.0: Poor

**CVaR (Conditional Value at Risk):**
- Expected loss in worst X% of scenarios
- Lower is better (less tail risk)
- CVaR95: Mean loss in worst 5% of days
- CVaR99: Mean loss in worst 1% of days

**VaR (Value at Risk):**
- Maximum loss at X% confidence level
- Lower is better
- VaR95: 95% confident losses won't exceed this
- VaR99: 99% confident losses won't exceed this

**Win Rate:**
- Percentage of profitable trades
- 50-60%: Average
- >60%: Good
- >70%: Excellent

**Profit Factor:**
- Ratio of gross profits to gross losses
- >2.0: Excellent
- 1.5-2.0: Good
- 1.0-1.5: Break-even
- <1.0: Losing strategy

### Testing

**Test File Location:**
- Unit tests: `tests/finance/metrics/test_core.py`
- Integration tests: `tests/finance/test_performance_tracker.py`
- Property tests: `tests/finance/metrics/test_metric_properties.py`

**Test Standards:**
- Test each metric with known datasets
- Test edge cases (zero trades, all winners, all losers)
- Test integration with PerformanceTracker
- Test report generation includes new metrics

**Testing Frameworks:**
- pytest for test framework
- hypothesis for property-based testing
- Polars for test data generation
- Decimal for assertions

**Manual Verification:**
1. Run sample backtest
2. Print performance summary
3. Verify all new metrics displayed
4. Compare metric values with manual calculations
5. Test with different strategies (winning, losing, mixed)

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-30 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
