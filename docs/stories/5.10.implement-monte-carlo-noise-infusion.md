# Story 5.10: Implement Monte Carlo Simulation with Noise Infusion

## Status
Draft

## Story
**As a** quantitative trader,
**I want** Monte Carlo simulation with noise infusion (perturb price data),
**so that** I can validate strategy isn't overfit to specific historical price patterns.

## Acceptance Criteria
1. NoiseInfusionSimulator adds synthetic noise to price data and re-runs backtest
2. Noise models supported: Gaussian noise (add random returns), bootstrap historical returns
3. Noise amplitude configurable (e.g., ±1% price perturbation per bar)
4. Temporal structure preserved (don't break autocorrelation or trend patterns completely)
5. Multiple noise realizations generated (N simulations with different noise seeds)
6. Performance distribution generated showing robustness to noisy data
7. Degradation analysis: how much does performance degrade with noise?
8. Tests validate noise infusion doesn't break OHLCV relationships or temporal ordering
9. Example demonstrates strategy robust to noise vs. strategy failing with noise
10. Documentation explains noise infusion as robustness test (like regularization in ML)

## Tasks / Subtasks
- [ ] Implement NoiseInfusionSimulator class (AC: 1, 2, 3)
  - [ ] Create rustybt/optimization/noise_infusion.py (or extend monte_carlo.py)
  - [ ] Define NoiseInfusionSimulator class
  - [ ] Configure noise amplitude (std_pct parameter, e.g., 0.01 for 1%)
  - [ ] Implement Gaussian noise model (add random returns)
  - [ ] Implement bootstrap noise model (resample historical returns)
  - [ ] Apply noise to price data (OHLCV bars)
  - [ ] Validate OHLCV relationships after noise (high ≥ low, etc.)
  - [ ] Support random seed for reproducibility
- [ ] Implement Gaussian noise model (AC: 2)
  - [ ] Generate random returns from N(0, std_pct) for each bar
  - [ ] Add noise to close prices: close_noisy = close * (1 + noise)
  - [ ] Adjust OHLCV proportionally to maintain relationships
  - [ ] Ensure high ≥ low, high ≥ open/close, low ≤ open/close
  - [ ] Preserve volume (or add proportional noise if needed)
- [ ] Implement bootstrap noise model (AC: 2)
  - [ ] Extract historical returns: returns = close.pct_change()
  - [ ] Resample returns with replacement (bootstrap)
  - [ ] Add resampled returns as noise: close_noisy = close * (1 + noise_returns)
  - [ ] Adjust OHLCV to maintain relationships
  - [ ] Preserves empirical return distribution
- [ ] Preserve temporal structure (AC: 4)
  - [ ] Optional: Preserve autocorrelation (use ARMA noise model)
  - [ ] Optional: Preserve trend (add noise to detrended series, re-add trend)
  - [ ] Document temporal structure preservation options
  - [ ] Default: Simple additive noise (may break some structure)
  - [ ] Advanced: ARMA noise (preserves autocorrelation)
- [ ] Generate multiple noise realizations (AC: 5)
  - [ ] Run N simulations with different random seeds
  - [ ] For each simulation: add noise → run backtest → record metrics
  - [ ] Collect performance metrics across simulations
  - [ ] Generate distribution of Sharpe ratios, returns, drawdowns
- [ ] Generate performance distribution (AC: 6)
  - [ ] Histogram of Sharpe ratios across noise realizations
  - [ ] Calculate mean, median, std of performance metrics
  - [ ] Compare to original (noise-free) backtest
  - [ ] Visualize distribution with original result marked
- [ ] Implement degradation analysis (AC: 7)
  - [ ] Calculate performance drop: (original_sharpe - noisy_mean_sharpe) / original_sharpe
  - [ ] Flag high degradation (>50%) as overfit indicator
  - [ ] Calculate worst-case performance (5th percentile)
  - [ ] Report: "Strategy degrades X% with Y% noise"
- [ ] Validate OHLCV constraints (AC: 8)
  - [ ] Test: high ≥ low for all bars
  - [ ] Test: high ≥ open, close for all bars
  - [ ] Test: low ≤ open, close for all bars
  - [ ] Test: close[t] → open[t+1] relationship reasonable
  - [ ] Test: volume ≥ 0 for all bars
  - [ ] Reject or fix invalid bars
- [ ] Create example notebook (AC: 9)
  - [ ] Create examples/optimization/noise_infusion_robustness.ipynb
  - [ ] Demonstrate robust strategy (performance stable with noise)
  - [ ] Demonstrate overfit strategy (performance collapses with noise)
  - [ ] Show performance distributions for both
  - [ ] Visualize degradation analysis
  - [ ] Interpret results (robust vs. fragile)
- [ ] Add documentation (AC: 10)
  - [ ] Explain noise infusion as robustness test
  - [ ] Analogy to regularization in ML (test generalization)
  - [ ] Document interpretation guide (degradation %, CI)
  - [ ] Explain Gaussian vs. bootstrap noise (when to use each)
  - [ ] Add usage examples with different noise levels

## Dev Notes

### Previous Story Context
[Source: Story 5.1-5.9]
- Optimization finds best parameters
- Walk-forward validates temporal robustness
- Sensitivity validates parameter robustness
- Monte Carlo permutation validates statistical robustness
- Noise infusion validates robustness to data perturbations

### Relevant Source Tree Info
[Source: [source-tree.md](docs/architecture/source-tree.md#L106-L117)]
File location: `rustybt/optimization/noise_infusion.py` (or extend monte_carlo.py)

Test location: `tests/optimization/test_noise_infusion.py`

Example location: `examples/optimization/noise_infusion_robustness.ipynb`

### Noise Infusion Concept
[Source: AC 1]

**Question**: Is strategy overfit to specific historical price patterns?

**Method**:
1. Take historical price data
2. Add synthetic noise (random perturbations)
3. Re-run backtest on noisy data
4. Repeat N times with different noise
5. Analyze performance degradation

**Interpretation**:
- Small degradation (5-10%) → Robust strategy
- Large degradation (>50%) → Overfit to noise-free patterns

**Analogy to ML**: Like testing model on data with augmentation/noise (robustness check).

### Gaussian Noise Model
[Source: AC 2]

**Add random returns**:
```python
import numpy as np

# Original close prices
close = data['close'].to_numpy()

# Generate noise (N(0, std_pct) returns)
noise = np.random.normal(0, std_pct, size=len(close))

# Add noise to prices
close_noisy = close * (1 + noise)

# Adjust OHLC proportionally
factor = close_noisy / close
open_noisy = data['open'] * factor
high_noisy = data['high'] * factor
low_noisy = data['low'] * factor
```

**Validate OHLCV**:
```python
# Ensure high ≥ low
assert (high_noisy >= low_noisy).all()
# Ensure high ≥ open, close
assert (high_noisy >= open_noisy).all()
assert (high_noisy >= close_noisy).all()
# Ensure low ≤ open, close
assert (low_noisy <= open_noisy).all()
assert (low_noisy <= close_noisy).all()
```

### Bootstrap Noise Model
[Source: AC 2]

**Resample historical returns**:
```python
# Extract returns
returns = data['close'].pct_change().dropna()

# Bootstrap sample returns (with replacement)
noise_returns = np.random.choice(returns, size=len(close), replace=True)

# Add noise
close_noisy = close * (1 + noise_returns)
```

**Advantage**: Preserves empirical return distribution (fat tails, skewness).

### Noise Amplitude Configuration
[Source: AC 3]

**std_pct parameter**:
- 0.005 (0.5%) → Very mild noise
- 0.01 (1%) → Moderate noise (default)
- 0.02 (2%) → Aggressive noise
- 0.05 (5%) → Extreme noise (stress test)

**Guideline**:
- Start with 1% noise
- If strategy robust, increase to 2-5%
- If strategy fails at 1%, it's overfit

### Temporal Structure Preservation
[Source: AC 4]

**Challenge**: Simple additive noise breaks autocorrelation and trends.

**Basic approach** (may break structure):
```python
# Just add noise (simple, but breaks autocorrelation)
close_noisy = close * (1 + noise)
```

**Advanced approach** (preserve autocorrelation):
```python
from statsmodels.tsa.arima.model import ARIMA

# Fit ARMA to returns
model = ARIMA(returns, order=(1, 0, 1))
fitted = model.fit()

# Simulate ARMA noise (preserves autocorrelation)
arma_noise = fitted.simulate(nsimulations=len(returns), repetitions=1)
close_noisy = close * (1 + arma_noise)
```

**Trade-off**: Simple noise easier but less realistic, ARMA preserves structure but complex.

### Multiple Noise Realizations
[Source: AC 5]

**Run N simulations**:
```python
n_simulations = 1000
sharpe_ratios = []

for i in range(n_simulations):
    # Generate noise with different seed
    noisy_data = add_noise(data, std_pct=0.01, seed=i)

    # Run backtest on noisy data
    result = run_backtest(strategy, noisy_data, params)

    sharpe_ratios.append(result['sharpe_ratio'])

# Analyze distribution
mean_sharpe = np.mean(sharpe_ratios)
std_sharpe = np.std(sharpe_ratios)
```

### Performance Distribution
[Source: AC 6]

**Metrics to track**:
- Sharpe ratio distribution
- Total return distribution
- Max drawdown distribution
- Win rate distribution

**Visualization**:
```python
import matplotlib.pyplot as plt

plt.hist(sharpe_ratios, bins=50, alpha=0.7, label='Noisy')
plt.axvline(original_sharpe, color='red', linewidth=2, label='Original')
plt.xlabel('Sharpe Ratio')
plt.ylabel('Frequency')
plt.title(f'Noise Infusion Test (std={std_pct*100:.1f}%)')
plt.legend()
```

### Degradation Analysis
[Source: AC 7]

**Performance degradation**:
```python
original_sharpe = 2.0
noisy_mean_sharpe = 1.6

degradation_pct = (original_sharpe - noisy_mean_sharpe) / original_sharpe * 100
# degradation_pct = 20%

if degradation_pct > 50:
    print("WARNING: Strategy highly sensitive to noise (likely overfit)")
elif degradation_pct > 25:
    print("CAUTION: Moderate noise sensitivity")
else:
    print("ROBUST: Strategy tolerates noise well")
```

**Worst-case analysis**:
```python
worst_case_sharpe = np.percentile(sharpe_ratios, 5)  # 5th percentile
print(f"Worst case (5th percentile): {worst_case_sharpe:.2f}")
```

### OHLCV Relationship Validation
[Source: AC 8]

**Constraints**:
1. high ≥ low (always)
2. high ≥ open (always)
3. high ≥ close (always)
4. low ≤ open (always)
5. low ≤ close (always)
6. volume ≥ 0 (always)
7. close[t] ≈ open[t+1] (usually, gaps allowed)

**Fix violations**:
```python
def fix_ohlcv_relationships(ohlcv):
    """Ensure OHLCV constraints after noise."""
    high = ohlcv['high'].copy()
    low = ohlcv['low'].copy()
    open_ = ohlcv['open'].copy()
    close = ohlcv['close'].copy()

    # Adjust high to be max of all
    high = np.maximum.reduce([high, open_, close])

    # Adjust low to be min of all
    low = np.minimum.reduce([low, open_, close])

    # Ensure high ≥ low
    high = np.maximum(high, low + 1e-8)

    return {'open': open_, 'high': high, 'low': low, 'close': close, 'volume': ohlcv['volume']}
```

### Robust vs. Fragile Strategy Examples
[Source: AC 9]

**Robust strategy** (trend following):
- Original Sharpe: 1.5
- Noisy mean Sharpe: 1.4
- Degradation: 7%
- Interpretation: Captures broad trends, tolerates noise

**Fragile strategy** (pattern matching):
- Original Sharpe: 2.0
- Noisy mean Sharpe: 0.5
- Degradation: 75%
- Interpretation: Overfit to specific price patterns, fails with perturbations

### Noise Infusion as Regularization
[Source: AC 10]

**Analogy to ML**:
- ML: Add noise to training data → test generalization
- Trading: Add noise to backtest data → test robustness

**Interpretation**:
- Robust strategy = generalizes beyond historical data
- Fragile strategy = memorized historical patterns (overfit)

**Use case**: Validate optimization results before live trading.

### Tech Stack
[Source: [tech-stack.md](docs/architecture/tech-stack.md)]
- numpy for noise generation
- Polars for data manipulation
- statsmodels for ARMA noise (optional)
- matplotlib for visualization

### Testing

#### Test File Location
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L441-L444)]
Tests at: `tests/optimization/test_noise_infusion.py`

#### Coverage Requirements
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L7)]
- **New Components**: ≥90% strict enforcement

#### OHLCV Validation Test
[Source: AC 8]
```python
def test_noise_preserves_ohlcv_relationships():
    """Noisy data must satisfy OHLCV constraints."""
    import polars as pl

    data = pl.DataFrame({
        'open': [100, 101, 102],
        'high': [105, 106, 107],
        'low': [99, 100, 101],
        'close': [103, 104, 105],
        'volume': [1000, 1100, 1200]
    })

    sim = NoiseInfusionSimulator(std_pct=0.01, seed=42)
    noisy_data = sim.add_noise(data)

    # Validate constraints
    assert (noisy_data['high'] >= noisy_data['low']).all()
    assert (noisy_data['high'] >= noisy_data['open']).all()
    assert (noisy_data['high'] >= noisy_data['close']).all()
    assert (noisy_data['low'] <= noisy_data['open']).all()
    assert (noisy_data['low'] <= noisy_data['close']).all()
    assert (noisy_data['volume'] >= 0).all()
```

#### Degradation Analysis Test
[Source: AC 7]
```python
def test_degradation_analysis():
    """Calculate performance degradation with noise."""

    # Robust synthetic strategy (not noise-sensitive)
    def robust_strategy_backtest(data):
        # Simple trend following, robust to noise
        return {'sharpe_ratio': 1.5}  # Consistent regardless of noise

    sim = NoiseInfusionSimulator(n_simulations=100, std_pct=0.01)
    results = sim.run(data, robust_strategy_backtest)

    # Robust strategy should have low degradation
    degradation = results.degradation_pct
    assert degradation < 20  # <20% degradation
```

#### Property Tests
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L26-L85)]
```python
@given(
    std_pct=st.floats(min_value=0.001, max_value=0.1)
)
def test_noise_amplitude_scaling(std_pct):
    """Higher noise amplitude should increase variance."""
    data = generate_test_data()

    sim1 = NoiseInfusionSimulator(std_pct=std_pct, seed=42)
    sim2 = NoiseInfusionSimulator(std_pct=std_pct*2, seed=42)

    noisy1 = sim1.add_noise(data)
    noisy2 = sim2.add_noise(data)

    var1 = (noisy1['close'] - data['close']).var()
    var2 = (noisy2['close'] - data['close']).var()

    # Double noise amplitude → higher variance
    assert var2 > var1
```

#### Zero-Mock Enforcement
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L137-L212)]
- No mocked noise generation
- Tests use real numpy.random for noise
- Validation tests run actual backtests on noisy data

### Documentation

#### Docstring Example
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L48-L74)]
```python
class NoiseInfusionSimulator:
    """Monte Carlo simulation with noise infusion for robustness testing.

    Tests if strategy is overfit to specific historical price patterns by
    adding synthetic noise to data and measuring performance degradation.

    Best for:
        - Validating backtest robustness
        - Detecting overfitting to price patterns
        - Stress testing strategies
        - Assessing generalization beyond historical data

    Args:
        n_simulations: Number of noise realizations (default: 1000)
        std_pct: Noise amplitude as % of price (default: 0.01 = 1%)
        noise_model: 'gaussian' or 'bootstrap' (default: 'gaussian')
        seed: Random seed for reproducibility (optional)

    Example:
        >>> # Run original backtest
        >>> result = run_backtest(strategy, data)
        >>> original_sharpe = result['sharpe_ratio']
        >>>
        >>> # Noise infusion test
        >>> sim = NoiseInfusionSimulator(n_simulations=1000, std_pct=0.01, seed=42)
        >>> results = sim.run(data, lambda d: run_backtest(strategy, d))
        >>>
        >>> print(f"Original Sharpe: {original_sharpe:.2f}")
        >>> print(f"Noisy Mean Sharpe: {results.mean_sharpe:.2f}")
        >>> print(f"Degradation: {results.degradation_pct:.1f}%")
        >>>
        >>> if results.degradation_pct < 20:
        ...     print("Strategy is robust to noise!")
        >>> else:
        ...     print("Strategy may be overfit to price patterns")
    """
```

#### Architecture Documentation
Add to docs/architecture/optimization.md:
- Noise infusion concept and benefits
- Interpretation guide (degradation %, robust vs. fragile)
- Gaussian vs. bootstrap noise comparison
- Analogy to ML regularization

### Type Hints and Validation
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L9-L25)]
- 100% type hint coverage
- pydantic models for config validation
- mypy --strict compliance

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-02 | 1.0 | Initial story creation | Bob (SM Agent) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
