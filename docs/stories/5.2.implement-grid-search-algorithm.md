# Story 5.2: Implement Grid Search Algorithm

## Status
Draft

## Story
**As a** quantitative trader,
**I want** exhaustive grid search over parameter space,
**so that** I can systematically explore all parameter combinations for small parameter sets.

## Acceptance Criteria
1. GridSearchAlgorithm implements SearchAlgorithm interface
2. Parameter grid specification (discrete values per parameter: e.g., lookback=[10, 20, 30])
3. Exhaustive combination generation (Cartesian product of all parameter values)
4. Progress tracking (N/M combinations complete)
5. Early stopping optional (stop if best result plateaus)
6. Results sorted by objective function (e.g., Sharpe ratio descending)
7. Parallel execution supported (distribute grid cells across workers)
8. Tests validate complete grid coverage and result ordering
9. Example notebook demonstrates grid search on simple moving average crossover strategy
10. Documentation warns about combinatorial explosion for large parameter spaces

## Tasks / Subtasks
- [ ] Implement GridSearchAlgorithm class (AC: 1, 2, 3)
  - [ ] Create rustybt/optimization/search/grid_search.py
  - [ ] Define GridSearchAlgorithm inheriting from SearchAlgorithm base class
  - [ ] Implement parameter grid specification using pydantic models
  - [ ] Implement Cartesian product generation using itertools.product
  - [ ] Implement suggest() method returning next parameter combination
  - [ ] Implement update() method recording result for completed parameter set
  - [ ] Implement is_complete() method checking if all combinations tested
- [ ] Add progress tracking (AC: 4)
  - [ ] Track total combinations count (M)
  - [ ] Track completed combinations count (N)
  - [ ] Implement progress property returning N/M ratio
  - [ ] Add progress logging at configurable intervals
- [ ] Implement early stopping (AC: 5)
  - [ ] Add optional early_stopping_rounds parameter
  - [ ] Track best result over last N rounds
  - [ ] Stop optimization if no improvement in early_stopping_rounds
  - [ ] Document early stopping behavior
- [ ] Add result sorting and retrieval (AC: 6)
  - [ ] Store results with parameters and objective values
  - [ ] Sort results by objective function (descending for maximization)
  - [ ] Implement get_best_params() method
  - [ ] Implement get_results() method with optional top_k filtering
- [ ] Implement parallel execution support (AC: 7)
  - [ ] Make suggest() thread-safe for concurrent workers
  - [ ] Make update() thread-safe for result aggregation
  - [ ] Add test with multiprocessing to validate parallel safety
- [ ] Write comprehensive tests (AC: 8)
  - [ ] Test exhaustive grid coverage (all combinations generated)
  - [ ] Test result ordering by objective function
  - [ ] Test early stopping behavior
  - [ ] Test progress tracking accuracy
  - [ ] Test parallel execution correctness
  - [ ] Property test: grid size equals product of parameter counts
- [ ] Create example notebook (AC: 9)
  - [ ] Create examples/optimization/grid_search_ma_crossover.ipynb
  - [ ] Demonstrate grid search on moving average crossover strategy
  - [ ] Show parameter grid specification
  - [ ] Visualize results with heatmap or surface plot
  - [ ] Compare different parameter combinations
- [ ] Add documentation and warnings (AC: 10)
  - [ ] Document GridSearchAlgorithm in docs/architecture/optimization.md
  - [ ] Add docstrings with usage examples
  - [ ] Add warning about combinatorial explosion for >5 parameters
  - [ ] Document when to use grid search vs. random/Bayesian search

## Dev Notes

### Previous Story Context
[Source: Story 5.1]
- Optimization framework architecture defined in Story 5.1
- SearchAlgorithm abstract base class contract established
- ParameterSpace design completed
- Integration with backtest engine defined

### Relevant Source Tree Info
[Source: [source-tree.md](docs/architecture/source-tree.md#L106-L117)]
File location: `rustybt/optimization/search/grid_search.py`

Test location: `tests/optimization/search/test_grid_search.py`

Example location: `examples/optimization/grid_search_ma_crossover.ipynb`

### SearchAlgorithm Interface
[Source: Story 5.1, AC 2]
GridSearchAlgorithm must implement:
- `suggest() -> Dict[str, Any]`: Return next parameter combination to test
- `update(params: Dict[str, Any], result: float) -> None`: Record result for parameters
- `is_complete() -> bool`: Return True when all combinations tested

### Parameter Grid Specification
[Source: AC 2]
Support discrete parameter values:
```python
param_grid = {
    'lookback_short': [10, 20, 30],
    'lookback_long': [50, 100, 150],
    'threshold': [0.01, 0.02, 0.05]
}
# Total combinations: 3 × 3 × 3 = 27
```

### Cartesian Product Generation
[Source: AC 3]
Use `itertools.product` for efficient combination generation:
```python
from itertools import product

param_combinations = list(product(
    param_grid['lookback_short'],
    param_grid['lookback_long'],
    param_grid['threshold']
))
```

### Parallel Execution Requirements
[Source: AC 7, Story 5.1]
- Must be thread-safe for concurrent suggest() and update() calls
- Use threading.Lock for shared state protection
- Support multiprocessing for CPU-bound backtests

### Progress Tracking
[Source: AC 4]
Track and log progress:
- Total combinations (M): calculated from Cartesian product size
- Completed combinations (N): increment on each update()
- Progress ratio: N/M
- Log progress every 10% or configurable interval

### Early Stopping
[Source: AC 5]
Optional optimization:
- Track best objective value over sliding window
- Stop if no improvement in last `early_stopping_rounds`
- Saves computation when plateau reached

### Result Storage and Sorting
[Source: AC 6]
Store results for analysis:
- Each result: {params: Dict, objective: float, timestamp: datetime}
- Sort by objective (descending for max, ascending for min)
- Retrieve best parameters and top-k results

### Performance Considerations
[Source: Story 5.1]
- Grid search is exhaustive: O(n^k) where k is number of parameters
- Warn users about combinatorial explosion for >5 parameters
- Recommend random search or Bayesian for large spaces

### Integration with Backtest Engine
[Source: Story 5.1, AC 7]
For each parameter combination:
1. Get params from suggest()
2. Pass params to backtest via run_algorithm()
3. Extract objective metric from backtest result
4. Update grid search with result

### Checkpoint/Resume Support
[Source: Story 5.1, AC 6]
**Implementation Decision**: Checkpoint/resume support designed in Story 5.1 will be implemented in the base Optimizer class that wraps SearchAlgorithm instances, not in individual algorithm implementations. This keeps algorithm implementations simple and focused.

GridSearchAlgorithm should maintain state that can be serialized:
- Current position in grid (which combinations tested)
- Results collected so far
- Best parameters found

The Optimizer wrapper (from Story 5.1) will handle saving/loading this state to enable resume.

### Testing

#### Test File Location
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L441-L444)]
Tests at: `tests/optimization/search/test_grid_search.py`

#### Coverage Requirements
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L7)]
- **New Components**: ≥90% strict enforcement

#### Test Types
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L11-L24)]

**Unit Tests (70%)**:
- Test parameter grid parsing
- Test Cartesian product generation
- Test suggest()/update()/is_complete() methods
- Test progress tracking
- Test early stopping
- Test result sorting

**Integration Tests (25%)**:
- Test with real backtest engine integration
- Test parallel execution with multiprocessing

**Property Tests**:
```python
@given(
    param_counts=st.lists(st.integers(min_value=1, max_value=5), min_size=1, max_size=4)
)
def test_grid_size_invariant(param_counts):
    """Grid size must equal product of parameter value counts."""
    grid = GridSearchAlgorithm(...)
    expected_size = math.prod(param_counts)
    assert grid.total_combinations == expected_size
```

#### Zero-Mock Enforcement
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L137-L212)]
- No mocked suggest() or update() methods
- Tests must run actual grid search on real (simple) backtests
- No hardcoded return values

#### Parallel Execution Test
[Source: AC 7, AC 8]
```python
def test_grid_search_parallel_execution():
    """Validate thread-safety with concurrent workers."""
    grid = GridSearchAlgorithm(param_grid={...})

    def worker():
        while not grid.is_complete():
            params = grid.suggest()
            if params is None:
                break
            result = run_backtest(params)
            grid.update(params, result)

    with multiprocessing.Pool(4) as pool:
        pool.map(worker, range(4))

    assert grid.is_complete()
    assert len(grid.results) == grid.total_combinations
```

### Documentation

#### Docstring Example
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L48-L74)]
```python
class GridSearchAlgorithm(SearchAlgorithm):
    """Exhaustive grid search optimization algorithm.

    Systematically evaluates all combinations in a parameter grid.
    Best for small parameter spaces (<100 combinations).

    Warning:
        Grid size grows exponentially: O(n^k) where k is parameter count.
        Not recommended for >5 parameters or >1000 total combinations.
        Consider RandomSearch or BayesianOptimizer for large spaces.

    Example:
        >>> grid = GridSearchAlgorithm(
        ...     param_grid={
        ...         'lookback': [10, 20, 30],
        ...         'threshold': [0.01, 0.02]
        ...     },
        ...     objective='sharpe_ratio',
        ...     maximize=True
        ... )
        >>> while not grid.is_complete():
        ...     params = grid.suggest()
        ...     result = run_backtest(**params)
        ...     grid.update(params, result['sharpe_ratio'])
        >>> best_params = grid.get_best_params()
    """
```

#### Architecture Documentation
[Source: AC 10]
Add to docs/architecture/optimization.md:
- When to use grid search (small spaces, <100 combinations)
- Combinatorial explosion warning
- Comparison with random/Bayesian search
- Performance characteristics

### Example Notebook
[Source: AC 9]
Create `examples/optimization/grid_search_ma_crossover.ipynb`:
- Simple moving average crossover strategy
- Grid over short/long lookback periods
- Visualize results with heatmap
- Identify optimal parameter combination

### Type Hints and Validation
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L9-L25)]
- 100% type hint coverage
- Use pydantic for param_grid validation
- mypy --strict compliance

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-02 | 1.0 | Initial story creation | Bob (SM Agent) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
