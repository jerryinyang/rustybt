# Story 5.4: Implement Bayesian Optimization Algorithm

## Status
Draft

## Story
**As a** quantitative trader,
**I want** intelligent Bayesian optimization using Gaussian Process models,
**so that** I can efficiently find optimal parameters with fewer evaluations than grid/random search.

## Acceptance Criteria
1. BayesianOptimizer implements SearchAlgorithm interface using scikit-optimize library
2. Acquisition function configurable (Expected Improvement, Probability of Improvement, Upper Confidence Bound)
3. Prior knowledge supported (seed with known good parameters)
4. Exploration/exploitation tradeoff configurable (kappa parameter for UCB)
5. Surrogate model trained on completed evaluations to suggest next parameters
6. Convergence detection (stop when acquisition function improvement < threshold)
7. Visualization support (plot acquisition function and parameter importance)
8. Tests validate Bayesian optimization finds near-optimal parameters with <50% evaluations of grid search
9. Example demonstrates Bayesian optimization on 5-parameter strategy
10. Documentation explains Gaussian Process intuition and acquisition function selection

## Tasks / Subtasks
- [ ] Implement BayesianOptimizer class (AC: 1, 2, 5)
  - [ ] Create rustybt/optimization/search/bayesian_search.py
  - [ ] Define BayesianOptimizer inheriting from SearchAlgorithm base class
  - [ ] Install and import scikit-optimize (skopt)
  - [ ] Implement parameter space conversion to skopt.Space format
  - [ ] Support Real (continuous), Integer, Categorical parameter types
  - [ ] Implement acquisition function selection (EI, PI, UCB)
  - [ ] Initialize Gaussian Process surrogate model
  - [ ] Implement suggest() using skopt.Optimizer.ask()
  - [ ] Implement update() using skopt.Optimizer.tell()
  - [ ] Implement is_complete() based on iteration count or convergence
- [ ] Add acquisition function configuration (AC: 2, 4)
  - [ ] Support Expected Improvement (EI) acquisition function
  - [ ] Support Probability of Improvement (PI) acquisition function
  - [ ] Support Upper Confidence Bound (UCB) acquisition function
  - [ ] Add kappa parameter for UCB exploration/exploitation tradeoff
  - [ ] Add xi parameter for EI/PI exploration control
  - [ ] Document when to use each acquisition function
- [ ] Implement prior knowledge seeding (AC: 3)
  - [ ] Accept initial_points parameter (list of known good params)
  - [ ] Use skopt.Optimizer with x0/y0 for prior knowledge
  - [ ] Warm-start surrogate model with initial evaluations
  - [ ] Document how prior knowledge accelerates optimization
- [ ] Add convergence detection (AC: 6)
  - [ ] Track acquisition function values over iterations
  - [ ] Detect plateau (improvement < threshold for N consecutive iterations)
  - [ ] Early stop when converged
  - [ ] Log convergence status and iteration count
- [ ] Implement visualization support (AC: 7)
  - [ ] Add plot_convergence() method using skopt.plots
  - [ ] Add plot_objective() method for parameter importance
  - [ ] Add plot_evaluations() method for parameter vs. objective
  - [ ] Save plots to configurable output directory
  - [ ] Document visualization usage in docstrings
- [ ] Write comprehensive tests (AC: 8)
  - [ ] Test each acquisition function (EI, PI, UCB)
  - [ ] Test prior knowledge seeding improves convergence
  - [ ] Test convergence detection
  - [ ] Benchmark vs. Grid Search on known optimization problem
  - [ ] Verify Bayesian finds near-optimal with <50% evaluations
  - [ ] Test parallel execution if supported by skopt
  - [ ] Property test: suggestion respects parameter bounds
- [ ] Create example notebook (AC: 9)
  - [ ] Create examples/optimization/bayesian_optimization_5param.ipynb
  - [ ] Demonstrate Bayesian optimization on 5-parameter strategy
  - [ ] Compare with Grid Search and Random Search
  - [ ] Show convergence plots
  - [ ] Show parameter importance plots
  - [ ] Demonstrate prior knowledge seeding
- [ ] Add documentation (AC: 10)
  - [ ] Explain Gaussian Process intuition (fit probability distribution over functions)
  - [ ] Explain acquisition functions (balance exploration/exploitation)
  - [ ] Document when to use Bayesian optimization (expensive objectives, <20 params)
  - [ ] Add usage examples with different acquisition functions
  - [ ] Document recommended iteration counts (10-100× parameter count)

## Dev Notes

### Previous Story Context
[Source: Story 5.1, Story 5.2, Story 5.3]
- Optimization framework architecture defined in Story 5.1
- SearchAlgorithm interface implemented by GridSearchAlgorithm and RandomSearchAlgorithm
- Grid Search exhaustive but expensive (O(n^k))
- Random Search efficient for high dimensions but no learning

### Relevant Source Tree Info
[Source: [source-tree.md](docs/architecture/source-tree.md#L106-L117)]
File location: `rustybt/optimization/search/bayesian_search.py`

Test location: `tests/optimization/search/test_bayesian_search.py`

Example location: `examples/optimization/bayesian_optimization_5param.ipynb`

### SearchAlgorithm Interface
[Source: Story 5.1, AC 2]
BayesianOptimizer must implement:
- `suggest() -> Dict[str, Any]`: Return next parameter sample based on acquisition function
- `update(params: Dict[str, Any], result: float) -> None`: Update surrogate model with result
- `is_complete() -> bool`: Return True when converged or max iterations reached

### Gaussian Process Surrogate Model
Bayesian optimization models the objective function as a Gaussian Process:
- Mean function: Expected objective value at each point
- Covariance function: Uncertainty/variance at each point
- Updates model with each evaluation
- Uses model to suggest next evaluation point

### Acquisition Functions
[Source: AC 2]

**Expected Improvement (EI)** - Default, balanced:
```python
acquisition='EI'
```
Maximizes expected improvement over current best.

**Probability of Improvement (PI)** - Conservative:
```python
acquisition='PI'
```
Maximizes probability of improving over current best.

**Upper Confidence Bound (UCB)** - Exploration control:
```python
acquisition='LCB'  # or 'UCB' depending on skopt version
kappa=1.96  # Higher kappa = more exploration
```
Balances mean and uncertainty (mean + kappa * std).

### Parameter Space Definition
[Source: AC 1]
Convert to skopt.space.Space:
```python
from skopt.space import Real, Integer, Categorical

space = [
    Real(10, 100, name='lookback_short'),
    Real(50, 200, name='lookback_long'),
    Real(0.01, 0.1, name='threshold', prior='log-uniform'),
    Integer(1, 10, name='rebalance_freq'),
    Categorical(['ema', 'sma'], name='ma_type')
]
```

### Prior Knowledge Seeding
[Source: AC 3]
```python
from skopt import Optimizer

# Known good parameters from previous runs
x0 = [[20, 100, 0.02, 5, 'ema']]
y0 = [1.5]  # Sharpe ratio

optimizer = Optimizer(space, base_estimator='GP', acq_func='EI', x0=x0, y0=y0)
```

### Exploration/Exploitation Tradeoff
[Source: AC 4]

**Kappa parameter (UCB)**:
- kappa=0.0: Pure exploitation (greedy)
- kappa=1.96: Balanced (95% confidence interval)
- kappa=3.0: High exploration

**Xi parameter (EI/PI)**:
- xi=0.0: Exploit (prefer known good regions)
- xi=0.01: Balanced (default)
- xi=0.1: Explore (prefer uncertain regions)

### Convergence Detection
[Source: AC 6]
Stop optimization when:
1. Max iterations reached (n_iter), OR
2. Acquisition function improvement < threshold for N iterations (plateau)

```python
if len(acq_values) > patience:
    recent_improvement = max(acq_values[-patience:]) - acq_values[-1]
    if recent_improvement < convergence_threshold:
        converged = True
```

### Visualization
[Source: AC 7]
scikit-optimize provides built-in plotting:
```python
from skopt.plots import plot_convergence, plot_objective, plot_evaluations

plot_convergence(optimizer.get_result())
plot_objective(optimizer.get_result())
plot_evaluations(optimizer.get_result())
```

### Checkpoint/Resume Support
[Source: Story 5.1, AC 6]
**Implementation Decision**: Checkpoint/resume support designed in Story 5.1 will be implemented in the base Optimizer class that wraps SearchAlgorithm instances, not in individual algorithm implementations.

BayesianOptimizer should maintain serializable state:
- scikit-optimize Optimizer object (includes Gaussian Process model)
- Iteration counter
- All previous evaluations (X, y pairs)
- Best parameters found
- Convergence history

The Optimizer wrapper (from Story 5.1) will handle saving/loading this state. scikit-optimize supports pickling of Optimizer state for seamless resume.

### Performance Comparison
[Source: AC 8]

Research finding (Snoek et al., 2012):
> "Bayesian optimization can find good hyperparameters in 10-20 evaluations, compared to 100+ for random search."

Test scenario:
- 5D Rastrigin function (known global optimum)
- Bayesian: Find within 5% of optimum in 50 evaluations
- Grid Search (5^5=3125 points): Needs 1562 evaluations for same accuracy
- Speedup: 31× faster

### When to Use Bayesian Optimization
[Source: AC 10]

**Use Bayesian Optimization when:**
1. Expensive objective function (each backtest takes minutes)
2. Moderate parameter count (2-20 parameters)
3. Continuous parameters
4. Want sample efficiency (fewer evaluations)
5. Can afford sequential optimization (not massively parallel)

**Don't use when:**
1. Very cheap objective (<1 second per eval) → Random Search faster
2. Very high dimensions (>20 params) → Curse of dimensionality
3. Need strict guarantees → Grid Search for exhaustive coverage
4. Massively parallel (1000+ workers) → Random Search parallelizes better

### Tech Stack
[Source: [tech-stack.md](docs/architecture/tech-stack.md)]
- **scikit-optimize (skopt)**: Bayesian optimization library
- numpy for numerical operations
- matplotlib for visualization
- scipy for Gaussian Process backend

### Dependency Installation
Add to pyproject.toml:
```toml
[project.optional-dependencies]
optimization = [
    "scikit-optimize>=0.9.0",
]
```

### Testing

#### Test File Location
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L441-L444)]
Tests at: `tests/optimization/search/test_bayesian_search.py`

#### Coverage Requirements
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L7)]
- **New Components**: ≥90% strict enforcement

#### Benchmark Test
[Source: AC 8]
```python
def test_bayesian_efficiency_vs_grid():
    """Bayesian finds near-optimal with <50% evaluations of grid search."""

    # 5D test function with known optimum
    def rastrigin_5d(params):
        x = [params[f'x{i}'] for i in range(5)]
        return -sum(x_i**2 - 10*np.cos(2*np.pi*x_i) for x_i in x)

    # Grid search baseline (5^5 = 3125 points)
    grid = GridSearchAlgorithm(param_grid={f'x{i}': [-5, -2.5, 0, 2.5, 5] for i in range(5)})
    grid_evals = run_optimization(grid, rastrigin_5d)
    grid_best = grid.get_best_result()

    # Bayesian optimization (50 iterations)
    bayes = BayesianOptimizer(
        space=[Real(-5, 5, name=f'x{i}') for i in range(5)],
        n_iter=50,
        acq_func='EI'
    )
    bayes_evals = run_optimization(bayes, rastrigin_5d)
    bayes_best = bayes.get_best_result()

    # Bayesian should be within 5% of grid search best
    assert bayes_best >= 0.95 * grid_best
    # Bayesian should use <50% evaluations
    assert bayes_evals < 0.5 * grid_evals
```

#### Property Tests
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L26-L85)]
```python
@given(
    n_params=st.integers(min_value=2, max_value=5),
    n_iter=st.integers(min_value=10, max_value=50)
)
def test_suggestions_respect_bounds(n_params, n_iter):
    """All suggestions must be within parameter bounds."""
    space = [Real(0, 1, name=f'x{i}') for i in range(n_params)]
    optimizer = BayesianOptimizer(space=space, n_iter=n_iter)

    for _ in range(n_iter):
        params = optimizer.suggest()
        # All parameters in [0, 1]
        assert all(0 <= params[f'x{i}'] <= 1 for i in range(n_params))
        # Update with dummy result
        optimizer.update(params, np.random.random())
```

#### Zero-Mock Enforcement
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L137-L212)]
- No mocked Gaussian Process models
- Tests use real scikit-optimize Optimizer
- Benchmark tests run actual optimization on test functions

### Documentation

#### Docstring Example
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L48-L74)]
```python
class BayesianOptimizer(SearchAlgorithm):
    """Bayesian optimization using Gaussian Process surrogate models.

    Uses a Gaussian Process to model the objective function and an acquisition
    function to balance exploration (uncertain regions) and exploitation
    (promising regions). More sample-efficient than grid/random search.

    Best for:
        - Expensive objective functions (minutes per evaluation)
        - Moderate parameter count (2-20 parameters)
        - Sequential optimization (not massively parallel)
        - Continuous parameter spaces

    Args:
        space: List of skopt.space dimensions (Real, Integer, Categorical)
        n_iter: Maximum number of iterations
        acq_func: Acquisition function ('EI', 'PI', 'LCB')
        initial_points: Prior knowledge (optional)
        kappa: UCB exploration parameter (default: 1.96)

    Example:
        >>> from skopt.space import Real, Categorical
        >>> optimizer = BayesianOptimizer(
        ...     space=[
        ...         Real(10, 100, name='lookback'),
        ...         Real(0.01, 0.1, name='threshold', prior='log-uniform'),
        ...         Categorical(['ema', 'sma'], name='ma_type')
        ...     ],
        ...     n_iter=50,
        ...     acq_func='EI',
        ...     initial_points=[{'lookback': 20, 'threshold': 0.02, 'ma_type': 'ema'}]
        ... )
        >>> while not optimizer.is_complete():
        ...     params = optimizer.suggest()
        ...     result = run_backtest(**params)
        ...     optimizer.update(params, result['sharpe_ratio'])
        >>> best_params = optimizer.get_best_params()
    """
```

#### Architecture Documentation
[Source: AC 10]
Add to docs/architecture/optimization.md:
- Gaussian Process intuition (probability distribution over functions)
- Acquisition function comparison table
- When to use Bayesian vs. Grid vs. Random
- Example with visualization plots

### Type Hints and Validation
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L9-L25)]
- 100% type hint coverage
- pydantic models for config validation
- mypy --strict compliance

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-02 | 1.0 | Initial story creation | Bob (SM Agent) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
