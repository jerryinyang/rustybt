# Story 5.9: Implement Monte Carlo Simulation with Data Permutation

## Status
Draft

## Story
**As a** quantitative trader,
**I want** Monte Carlo simulation with data permutation (shuffling trade order),
**so that** I can validate strategy performance isn't due to lucky trade sequencing.

## Acceptance Criteria
1. MonteCarloSimulator runs N simulations with randomized trade sequences
2. Permutation method: shuffle trade order while preserving trade outcomes (win/loss/size)
3. Bootstrap method: resample trades with replacement to generate alternative sequences
4. Performance distribution generated across all simulations (histogram of Sharpe ratios)
5. Confidence intervals calculated (e.g., 95% CI for expected Sharpe ratio)
6. Statistical significance test: is observed performance > Nth percentile of random?
7. Tests validate permutation preserves trade statistics (same total return, different sequence)
8. Integration test demonstrates Monte Carlo on completed backtest
9. Visualization shows performance distribution vs. original backtest result
10. Documentation explains interpretation: if backtest outside 95% CI → likely robust

## Tasks / Subtasks
- [ ] Implement MonteCarloSimulator class (AC: 1, 2, 3)
  - [ ] Create rustybt/optimization/monte_carlo.py
  - [ ] Define MonteCarloSimulator class
  - [ ] Configure number of simulations (n_simulations parameter)
  - [ ] Implement trade permutation method (shuffle trade order)
  - [ ] Implement bootstrap resampling method (sample with replacement)
  - [ ] Extract trades from backtest results
  - [ ] Reconstruct performance from permuted trades
  - [ ] Support random seed for reproducibility
- [ ] Implement permutation method (AC: 2)
  - [ ] Extract trade list from backtest: [trade1, trade2, ..., tradeN]
  - [ ] Shuffle trade order using random permutation
  - [ ] Preserve trade outcomes (return, P&L, size)
  - [ ] Recalculate equity curve from shuffled trades
  - [ ] Recalculate performance metrics (Sharpe, drawdown, etc.)
  - [ ] Validate: sum(returns) same for original and permuted
- [ ] Implement bootstrap method (AC: 3)
  - [ ] Resample trades with replacement (same N trades)
  - [ ] Some trades appear multiple times, some not at all
  - [ ] Recalculate equity curve from resampled trades
  - [ ] Recalculate performance metrics
  - [ ] Validate: distribution statistics similar to permutation
- [ ] Generate performance distribution (AC: 4)
  - [ ] Run N simulations (default: 1000)
  - [ ] Collect Sharpe ratio from each simulation
  - [ ] Collect other metrics: total return, max drawdown, win rate
  - [ ] Create distribution: histogram of Sharpe ratios
  - [ ] Calculate distribution statistics: mean, median, std, skew
- [ ] Calculate confidence intervals (AC: 5)
  - [ ] 95% CI: 2.5th and 97.5th percentiles
  - [ ] 90% CI: 5th and 95th percentiles
  - [ ] Bootstrap CI: percentile method
  - [ ] Report CI for key metrics (Sharpe, return, drawdown)
- [ ] Implement statistical significance test (AC: 6)
  - [ ] Calculate percentile rank of observed result in distribution
  - [ ] Test: observed > 95th percentile → statistically significant
  - [ ] P-value: fraction of simulations with result ≥ observed
  - [ ] Flag insignificant results (likely due to luck)
- [ ] Write comprehensive tests (AC: 7)
  - [ ] Test permutation preserves total return
  - [ ] Test bootstrap generates valid equity curves
  - [ ] Test distribution statistics (mean, std)
  - [ ] Test confidence interval calculation
  - [ ] Test statistical significance detection
  - [ ] Property test: permutation doesn't change sum of returns
- [ ] Create integration test (AC: 8)
  - [ ] Run complete backtest on sample strategy
  - [ ] Extract trades from backtest result
  - [ ] Run Monte Carlo with permutation method
  - [ ] Verify simulation produces valid distributions
  - [ ] Test with both permutation and bootstrap methods
- [ ] Implement visualization (AC: 9)
  - [ ] Histogram of simulated Sharpe ratios
  - [ ] Mark observed Sharpe ratio on histogram
  - [ ] Show 95% confidence interval bands
  - [ ] Show p-value and percentile rank
  - [ ] Save plot to configurable output directory
- [ ] Add documentation (AC: 10)
  - [ ] Explain Monte Carlo permutation concept
  - [ ] Document interpretation guide (CI, p-value, percentile)
  - [ ] Explain when result is robust (outside 95% CI)
  - [ ] Document permutation vs. bootstrap (when to use each)
  - [ ] Add usage examples with interpretation

## Dev Notes

### Previous Story Context
[Source: Story 5.1-5.8]
- Optimization finds best parameters
- Walk-forward validates temporal robustness
- Sensitivity validates parameter robustness
- Monte Carlo validates statistical robustness (not just luck)

### Relevant Source Tree Info
[Source: [source-tree.md](docs/architecture/source-tree.md#L106-L117)]
File location: `rustybt/optimization/monte_carlo.py`

Test location: `tests/optimization/test_monte_carlo.py`

### Monte Carlo Permutation Concept
[Source: AC 2]

**Question**: Is strategy performance due to skill or lucky trade sequencing?

**Method**:
1. Extract trades from backtest: `[trade1, trade2, ..., tradeN]`
2. Shuffle trade order randomly: `[trade5, trade1, trade3, ...]`
3. Recalculate equity curve and metrics from shuffled trades
4. Repeat 1000 times → distribution of possible outcomes
5. Compare observed result to distribution

**Interpretation**:
- Observed Sharpe = 2.0, 95% CI = [0.5, 1.5] → Likely robust (outside CI)
- Observed Sharpe = 1.2, 95% CI = [0.8, 1.4] → Possibly lucky (inside CI)

### Permutation Method
[Source: AC 2]

**Preserve trade outcomes**:
```python
trades = [
    {'return': 0.02, 'pnl': 100, 'size': 1000},
    {'return': -0.01, 'pnl': -50, 'size': 1000},
    ...
]

# Shuffle order
import random
shuffled_trades = random.sample(trades, len(trades))

# Recalculate equity
equity = [initial_capital]
for trade in shuffled_trades:
    equity.append(equity[-1] + trade['pnl'])
```

**Invariant**: Sum of returns identical, but sequence differs.

### Bootstrap Method
[Source: AC 3]

**Resample with replacement**:
```python
import numpy as np

# Bootstrap sample (same size N, some trades repeated)
bootstrap_trades = np.random.choice(trades, size=len(trades), replace=True)

# Some trades may appear 0, 1, 2+ times
# Generates alternative "what if" scenarios
```

**Difference from permutation**:
- Permutation: Every trade appears exactly once (just reordered)
- Bootstrap: Some trades appear multiple times, some not at all

### Performance Distribution
[Source: AC 4]

**Generate distribution**:
```python
sharpe_ratios = []
for i in range(n_simulations):
    shuffled = shuffle_trades(trades)
    equity = reconstruct_equity(shuffled)
    sharpe = calculate_sharpe(equity)
    sharpe_ratios.append(sharpe)

# Distribution statistics
mean_sharpe = np.mean(sharpe_ratios)
std_sharpe = np.std(sharpe_ratios)
```

**Metrics to track**:
- Sharpe ratio distribution
- Total return distribution
- Max drawdown distribution
- Win rate distribution

### Confidence Intervals
[Source: AC 5]

**Percentile method**:
```python
sharpe_distribution = np.array(sharpe_ratios)

# 95% confidence interval
ci_lower = np.percentile(sharpe_distribution, 2.5)
ci_upper = np.percentile(sharpe_distribution, 97.5)

print(f"95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]")
```

**Interpretation**:
- Narrow CI → Consistent performance across permutations (robust)
- Wide CI → Performance varies widely (luck-dependent)

### Statistical Significance Test
[Source: AC 6]

**Percentile rank**:
```python
observed_sharpe = 2.0
percentile_rank = percentileofscore(sharpe_distribution, observed_sharpe)

if percentile_rank > 95:
    print("Statistically significant (p < 0.05)")
else:
    print("Not significant - could be due to luck")
```

**P-value**:
```python
# Fraction of simulations with Sharpe ≥ observed
p_value = np.mean(sharpe_distribution >= observed_sharpe)

if p_value < 0.05:
    print(f"Significant (p={p_value:.3f})")
```

### Permutation Invariants
[Source: AC 7]

**Must preserve**:
1. Total return: `sum(returns_original) == sum(returns_permuted)`
2. Trade count: `len(trades_original) == len(trades_permuted)`
3. Win/loss distribution: Same number of winning/losing trades

**Can differ**:
1. Trade sequence (that's the point!)
2. Equity curve shape
3. Drawdown profile
4. Sharpe ratio (due to return sequencing effects)

### Integration with Backtest
[Source: AC 8]

**Extract trades from backtest**:
```python
# Run backtest
result = run_backtest(strategy, data, params)

# Extract trades
trades = result.transactions  # List of executed trades
equity_curve = result.portfolio_value

# Run Monte Carlo
mc = MonteCarloSimulator(n_simulations=1000, method='permutation', seed=42)
mc_results = mc.run(trades)

print(f"Observed Sharpe: {result.sharpe_ratio:.2f}")
print(f"MC Mean Sharpe: {mc_results.mean_sharpe:.2f}")
print(f"95% CI: [{mc_results.ci_lower:.2f}, {mc_results.ci_upper:.2f}]")
print(f"P-value: {mc_results.p_value:.3f}")
```

### Visualization
[Source: AC 9]

**Histogram with annotations**:
```python
import matplotlib.pyplot as plt

plt.hist(sharpe_distribution, bins=50, alpha=0.7, label='Simulated')
plt.axvline(observed_sharpe, color='red', linewidth=2, label='Observed')
plt.axvline(ci_lower, color='green', linestyle='--', label='95% CI')
plt.axvline(ci_upper, color='green', linestyle='--')
plt.xlabel('Sharpe Ratio')
plt.ylabel('Frequency')
plt.title(f'Monte Carlo Permutation Test (p={p_value:.3f})')
plt.legend()
```

### Interpretation Guide
[Source: AC 10]

**Robust strategy indicators**:
1. Observed result **outside** 95% CI (e.g., observed > CI upper)
2. High percentile rank (>95th)
3. Low p-value (<0.05)
4. Narrow confidence interval (consistent across permutations)

**Luck indicators**:
1. Observed result **inside** 95% CI
2. Moderate percentile rank (50-90th)
3. High p-value (>0.10)
4. Wide confidence interval (high variance across permutations)

**Example interpretations**:
- Observed Sharpe = 2.5, 95% CI = [0.8, 1.6], p=0.01 → **Robust strategy**
- Observed Sharpe = 1.2, 95% CI = [0.9, 1.5], p=0.25 → **Possibly lucky**
- Observed Sharpe = 0.8, 95% CI = [0.9, 1.5], p=0.95 → **Unlucky (or poor strategy)**

### Permutation vs. Bootstrap
[Source: AC 3]

**Use Permutation when**:
- Want to test if observed sequence is special
- Preserve exact trade outcomes
- Test null hypothesis: "trade order doesn't matter"

**Use Bootstrap when**:
- Want to estimate sampling uncertainty
- Account for trade variability
- Generate confidence intervals for metrics

**Both methods valid**, permutation more common for sequence testing.

### Tech Stack
[Source: [tech-stack.md](docs/architecture/tech-stack.md)]
- numpy for random sampling and statistics
- scipy.stats for percentile calculations
- matplotlib for visualization

### Testing

#### Test File Location
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L441-L444)]
Tests at: `tests/optimization/test_monte_carlo.py`

#### Coverage Requirements
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L7)]
- **New Components**: ≥90% strict enforcement

#### Permutation Invariant Test
[Source: AC 7]
```python
def test_permutation_preserves_total_return():
    """Permutation must preserve total return."""
    trades = [
        {'return': 0.02, 'pnl': 100},
        {'return': -0.01, 'pnl': -50},
        {'return': 0.03, 'pnl': 150},
    ]

    mc = MonteCarloSimulator(n_simulations=100, method='permutation', seed=42)
    results = mc.run(trades)

    original_total_return = sum(t['return'] for t in trades)

    for sim in results.simulations:
        sim_total_return = sum(t['return'] for t in sim.trades)
        assert abs(sim_total_return - original_total_return) < 1e-10
```

#### Statistical Significance Test
[Source: AC 6]
```python
def test_statistical_significance_detection():
    """High observed result should be detected as significant."""

    # Create trades with positive bias
    trades = [{'return': 0.05, 'pnl': 50} for _ in range(20)]

    mc = MonteCarloSimulator(n_simulations=1000, method='permutation')
    results = mc.run(trades)

    # All permutations have same total return (0.05 * 20 = 1.0)
    # Sharpe depends on sequence, but should be consistently high

    # Observed should be within distribution (all permutations similar)
    # This test shows non-significance detection works
    observed_sharpe = 2.0  # Hypothetical
    # If observed is average, p_value should be ~0.5
```

#### Property Tests
[Source: [testing-strategy.md](docs/architecture/testing-strategy.md#L26-L85)]
```python
@given(
    returns=st.lists(st.floats(min_value=-0.1, max_value=0.1), min_size=10, max_size=50)
)
def test_permutation_preserves_sum(returns):
    """Sum of returns must be identical across permutations."""
    trades = [{'return': r, 'pnl': r * 1000} for r in returns]

    original_sum = sum(returns)

    import random
    random.seed(42)
    shuffled = random.sample(trades, len(trades))
    shuffled_sum = sum(t['return'] for t in shuffled)

    assert abs(original_sum - shuffled_sum) < 1e-10
```

#### Zero-Mock Enforcement
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L137-L212)]
- No mocked random shuffling
- Tests use real numpy.random for permutation
- Validation tests run actual Monte Carlo simulations

### Documentation

#### Docstring Example
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L48-L74)]
```python
class MonteCarloSimulator:
    """Monte Carlo simulation with trade permutation for robustness testing.

    Tests if strategy performance is due to skill or lucky trade sequencing
    by shuffling trade order and generating performance distribution.

    Best for:
        - Validating backtest results
        - Detecting luck vs. skill
        - Calculating confidence intervals for metrics
        - Statistical significance testing

    Args:
        n_simulations: Number of Monte Carlo runs (default: 1000)
        method: 'permutation' or 'bootstrap' (default: 'permutation')
        seed: Random seed for reproducibility (optional)

    Example:
        >>> # Run backtest
        >>> result = run_backtest(strategy, data)
        >>> trades = result.transactions
        >>>
        >>> # Monte Carlo simulation
        >>> mc = MonteCarloSimulator(n_simulations=1000, method='permutation', seed=42)
        >>> mc_results = mc.run(trades)
        >>>
        >>> print(f"Observed Sharpe: {result.sharpe_ratio:.2f}")
        >>> print(f"95% CI: [{mc_results.ci_lower:.2f}, {mc_results.ci_upper:.2f}]")
        >>> print(f"P-value: {mc_results.p_value:.3f}")
        >>>
        >>> if mc_results.p_value < 0.05:
        ...     print("Strategy is statistically robust!")
        >>> else:
        ...     print("Performance may be due to luck")
    """
```

#### Architecture Documentation
Add to docs/architecture/optimization.md:
- Monte Carlo permutation concept
- Interpretation guide (CI, p-value, percentile)
- When strategy is robust vs. lucky
- Permutation vs. bootstrap comparison

### Type Hints and Validation
[Source: [coding-standards.md](docs/architecture/coding-standards.md#L9-L25)]
- 100% type hint coverage
- pydantic models for config validation
- mypy --strict compliance

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-02 | 1.0 | Initial story creation | Bob (SM Agent) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_
