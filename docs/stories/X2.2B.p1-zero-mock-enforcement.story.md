# Story X2.2B: P1 Zero-Mock Enforcement

## Status
Draft

## Story

**As a** Software Engineer maintaining RustyBT's quality policy cornerstone,
**I want** mandatory zero-mock detection and enforcement with automated pre-commit and CI checks,
**so that** the codebase contains only real implementations, prevents technical debt via placeholder code, and enforces the zero-mock policy across all contributions.

## Acceptance Criteria

### Phase 1: Mock Detection Scripts

1. **Mock Pattern Detection Script Created**
   - Create `scripts/detect_mocks.py` with mock pattern detection
   - Detect function/class names containing: "mock", "fake", "stub", "dummy", "placeholder"
   - Support case-insensitive matching
   - Exclude test files: `tests/**/*.py`, `**/test_*.py`
   - Provide `--quick` mode (scan function names only) for pre-commit
   - Provide `--strict` mode (full AST analysis) for CI
   - Exit with code 1 if violations found, code 0 if clean
   - Output: violation count, file paths, line numbers, function names

2. **Hardcoded Value Detection Script Created**
   - Create `scripts/detect_hardcoded_values.py` with constant return detection
   - Detect functions that return only constants: `return 10`, `return True`, `return 1.5`, `return "constant"`
   - Use AST analysis to parse function bodies
   - Ignore test files and fixtures
   - Ignore functions with only `raise` statements (error-only functions are OK)
   - Provide `--fail-on-found` flag for CI enforcement
   - Exit with code 1 if violations found, code 0 if clean
   - Output: violation count, file paths, line numbers, function names, constant values

3. **Validation Function Testing Script Created**
   - Create `scripts/verify_validations.py` with validator testing framework
   - Detect functions with "validate", "check", "verify" in name
   - Generate test cases with invalid inputs (None, empty, wrong type, out of range)
   - Verify validators raise exceptions or return False for invalid data
   - Provide `--ensure-real-checks` flag for CI enforcement
   - Exit with code 1 if validators pass invalid data, code 0 if all validators work
   - Output: validator count, passing/failing validators, file paths, line numbers

4. **Result Uniqueness Testing Script Created**
   - Create `scripts/test_unique_results.py` with output uniqueness verification
   - Identify public functions (not starting with `_`)
   - Generate diverse input sets (vary each parameter)
   - Verify different inputs produce different outputs
   - Ignore functions with side effects only (return None)
   - Ignore randomized functions (document with `# zero-mock: randomized` comment)
   - Provide `--sample-size` parameter (default: 10 calls per function)
   - Exit with code 1 if functions produce identical outputs for different inputs
   - Output: function count, uniqueness violations, file paths, function names

### Phase 2: Pre-Commit Integration

5. **Pre-Commit Hook for Mock Detection**
   - Add `detect_mocks.py --quick` to `.pre-commit-config.yaml`
   - Hook runs on Python files only (`types: [python]`)
   - Hook excludes test files automatically
   - Hook provides clear error messages: "Mock pattern detected: {function_name} in {file}:{line}"
   - Hook execution time: < 2 seconds for typical commit
   - Test hook blocks commit with mock pattern (create test file, verify blocked, delete test file)

### Phase 3: Documentation & Policy

6. **Zero-Mock Policy Documented**
   - Add "Zero-Mock Enforcement Policy" section to CONTRIBUTING.md
   - Document forbidden patterns:
     - Function/class names: mock*, fake*, stub*, dummy*, placeholder*
     - Hardcoded returns: `return constant` (except error-only functions)
     - Always-pass validators: `return True` validators
     - Identical outputs: same output for all inputs
   - Document allowed patterns:
     - Real implementations with actual logic
     - Test fixtures in test files (explicitly excluded)
     - Error-only functions: `raise NotImplementedError` (no return value)
     - Randomized functions: document with `# zero-mock: randomized`
   - Provide examples of violations and fixes

7. **CI Workflow Prepared for X2.2C Integration**
   - Create `.github/workflows/zero-mock-enforcement.yml` (content only, not activated yet)
   - Workflow runs all 4 detection scripts in strict mode
   - Workflow configured as BLOCKING (required check for branch protection)
   - Workflow runs on: push, pull_request
   - Document activation instructions for X2.2C story
   - Test workflow locally with `act` tool (if available) or document testing procedure

### Integration Requirements

8. **Zero-Mock Detection Validates Clean Codebase**
   - Run all 4 scripts on current codebase → 0 violations found
   - If violations found: create remediation tasks (outside this story scope)
   - Document any existing violations with justification and suppression comments
   - Pre-commit hooks pass on sample commits (test with actual code changes)

9. **Detection Scripts Follow Existing Patterns**
   - Scripts use Python stdlib (ast, pathlib, argparse - no new dependencies)
   - Scripts provide clear CLI interface with `--help`
   - Scripts follow existing scripts/ directory patterns
   - Scripts have exit codes: 0 (pass), 1 (violations found), 2 (error)
   - Scripts output machine-readable format (optional JSON with `--json` flag)

10. **Development Workflow Integration**
    - Pre-commit hooks run fast (< 2s for typical commit)
    - Hooks provide clear error messages with line numbers and function names
    - Hooks can be bypassed for urgent fixes with `git commit --no-verify` (document in CONTRIBUTING.md)
    - Documentation guides contributors through zero-mock policy

### Quality Requirements

11. **Detection Scripts Are Tested**
    - Create `tests/scripts/test_detect_mocks.py` with unit tests
    - Test mock pattern detection (positive and negative cases)
    - Test hardcoded value detection (various constant types)
    - Test validator verification (passing and failing validators)
    - Test result uniqueness (identical and unique outputs)
    - Test CLI flags and exit codes
    - Test file exclusions (test files ignored)

12. **Documentation Is Comprehensive**
    - CONTRIBUTING.md zero-mock section is clear and actionable
    - Examples provided for violations and fixes
    - Suppression mechanism documented (comments for justified violations)
    - Pre-commit bypass documented for urgent fixes
    - CI workflow prepared with activation instructions for X2.2C

13. **No Regression Verified**
    - Full test suite passes: `pytest -m "not memory and not api_integration and not live and not ib_integration"`
    - Pre-commit hooks do not block legitimate commits
    - Detection scripts do not flag false positives (test fixtures, error-only functions)

## Tasks / Subtasks

- [ ] **Task 1: Create Mock Pattern Detection Script** (AC: 1)
  - [ ] Create `scripts/detect_mocks.py` with argparse CLI
  - [ ] Implement mock pattern detection (mock, fake, stub, dummy, placeholder)
  - [ ] Add `--quick` mode (function name scanning only)
  - [ ] Add `--strict` mode (full AST analysis)
  - [ ] Exclude test files automatically
  - [ ] Test script on sample code with mock patterns
  - [ ] Verify exit codes (0 = clean, 1 = violations)

- [ ] **Task 2: Create Hardcoded Value Detection Script** (AC: 2)
  - [ ] Create `scripts/detect_hardcoded_values.py` with argparse CLI
  - [ ] Implement AST-based constant return detection
  - [ ] Detect: `return 10`, `return True`, `return "constant"`, etc.
  - [ ] Ignore error-only functions (only `raise` statements)
  - [ ] Add `--fail-on-found` flag for CI
  - [ ] Test script on sample code with hardcoded returns
  - [ ] Verify output includes file, line, function, constant value

- [ ] **Task 3: Create Validation Function Testing Script** (AC: 3)
  - [ ] Create `scripts/verify_validations.py` with argparse CLI
  - [ ] Detect functions with "validate", "check", "verify" in name
  - [ ] Generate invalid test cases (None, empty, wrong type, out of range)
  - [ ] Verify validators raise exceptions or return False
  - [ ] Add `--ensure-real-checks` flag for CI
  - [ ] Test script on sample validators (passing and failing)
  - [ ] Verify output includes validator count, file, line, status

- [ ] **Task 4: Create Result Uniqueness Testing Script** (AC: 4)
  - [ ] Create `scripts/test_unique_results.py` with argparse CLI
  - [ ] Identify public functions (not starting with `_`)
  - [ ] Generate diverse input sets (vary parameters)
  - [ ] Verify different inputs → different outputs
  - [ ] Ignore functions returning None (side-effect only)
  - [ ] Add `--sample-size` parameter (default: 10)
  - [ ] Test script on sample functions (unique and identical outputs)
  - [ ] Verify output includes function count, violations, file, line

- [ ] **Task 5: Pre-Commit Hook Integration** (AC: 5)
  - [ ] Add `detect_mocks.py --quick` to `.pre-commit-config.yaml`
  - [ ] Configure hook: `types: [python]`, exclude test files
  - [ ] Test hook with sample mock pattern (should block commit)
  - [ ] Verify hook execution time < 2 seconds
  - [ ] Verify error messages are clear

- [ ] **Task 6: Zero-Mock Policy Documentation** (AC: 6)
  - [ ] Add "Zero-Mock Enforcement Policy" section to CONTRIBUTING.md
  - [ ] Document forbidden patterns with examples
  - [ ] Document allowed patterns with examples
  - [ ] Document suppression mechanism (`# zero-mock: randomized`)
  - [ ] Document pre-commit bypass (`--no-verify`)
  - [ ] Review policy with team for clarity

- [ ] **Task 7: Prepare CI Workflow for X2.2C** (AC: 7)
  - [ ] Create `.github/workflows/zero-mock-enforcement.yml`
  - [ ] Configure workflow: run all 4 scripts in strict mode
  - [ ] Configure workflow as BLOCKING (required check)
  - [ ] Add activation instructions in workflow comments
  - [ ] Test workflow locally with `act` tool (if available)
  - [ ] Document X2.2C activation steps

- [ ] **Task 8: Validate Clean Codebase** (AC: 8)
  - [ ] Run all 4 scripts on current codebase
  - [ ] Document any violations found with justification
  - [ ] Add suppression comments for justified violations
  - [ ] Verify all scripts report 0 violations (or suppressed)
  - [ ] Test pre-commit hooks on sample commits

- [ ] **Task 9: Unit Tests for Detection Scripts** (AC: 11)
  - [ ] Create `tests/scripts/test_detect_mocks.py`
  - [ ] Test mock pattern detection (positive/negative cases)
  - [ ] Test hardcoded value detection (various types)
  - [ ] Test validator verification (passing/failing)
  - [ ] Test result uniqueness (identical/unique outputs)
  - [ ] Test CLI flags and exit codes
  - [ ] Test file exclusions (test files ignored)

- [ ] **Task 10: Final Validation** (AC: 12-13)
  - [ ] Run full test suite → all pass
  - [ ] Verify CONTRIBUTING.md documentation is clear
  - [ ] Verify pre-commit hooks work correctly
  - [ ] Verify no false positives in detection
  - [ ] Create summary report of zero-mock enforcement

## Dev Notes

### Architecture Context

**Source:** [docs/architecture/coding-standards.md](../architecture/coding-standards.md)

**Zero-Mock Enforcement:**
- Cornerstone of RustyBT's quality policy
- Prevents technical debt via placeholder implementations
- Ensures real implementations in production code
- MANDATORY - not optional

**Python Version:** 3.12+ required

**Source:** [docs/architecture/source-tree.md](../architecture/source-tree.md)

**Relevant Source Locations:**
- Scripts: `scripts/` directory (detection scripts)
- Pre-commit config: `.pre-commit-config.yaml`
- CI workflows: `.github/workflows/` (prepared for X2.2C)
- Tests: `tests/scripts/` (unit tests for detection scripts)
- Documentation: `CONTRIBUTING.md`

### Technical Implementation Guidance

#### **Script 1: Mock Pattern Detection (detect_mocks.py)**

```python
#!/usr/bin/env python3
"""Detect mock/fake/stub patterns in production code.

Zero-Mock Enforcement: RustyBT does not allow mock/fake/stub
implementations in production code. All functions must have real implementations.

Usage:
    python scripts/detect_mocks.py --quick     # Fast scan (pre-commit)
    python scripts/detect_mocks.py --strict    # Full AST analysis (CI)
"""
import argparse
import ast
import sys
from pathlib import Path
from typing import List, Tuple

# Forbidden patterns (case-insensitive)
MOCK_PATTERNS = ["mock", "fake", "stub", "dummy", "placeholder"]

# Exclude test files
EXCLUDE_PATTERNS = ["tests/", "test_", "_test.py", "conftest.py"]


def is_test_file(file_path: Path) -> bool:
    """Check if file is a test file (should be excluded)."""
    path_str = str(file_path)
    return any(pattern in path_str for pattern in EXCLUDE_PATTERNS)


def detect_mock_patterns_quick(file_path: Path) -> List[Tuple[int, str, str]]:
    """Quick scan: search for mock patterns in function/class names.

    Returns: List of (line_number, name, pattern) tuples
    """
    violations = []
    try:
        content = file_path.read_text()
        tree = ast.parse(content, filename=str(file_path))

        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                name_lower = node.name.lower()
                for pattern in MOCK_PATTERNS:
                    if pattern in name_lower:
                        violations.append((node.lineno, node.name, pattern))
                        break
    except Exception as e:
        print(f"Warning: Failed to parse {file_path}: {e}", file=sys.stderr)

    return violations


def main():
    parser = argparse.ArgumentParser(description="Detect mock/fake/stub patterns")
    parser.add_argument("--quick", action="store_true", help="Quick scan (function names only)")
    parser.add_argument("--strict", action="store_true", help="Full AST analysis (not implemented yet)")
    parser.add_argument("--json", action="store_true", help="Output JSON format")
    args = parser.parse_args()

    # Find all Python files
    project_root = Path(__file__).parent.parent
    python_files = list(project_root.glob("rustybt/**/*.py"))

    # Filter out test files
    python_files = [f for f in python_files if not is_test_file(f)]

    all_violations = []
    for file_path in python_files:
        violations = detect_mock_patterns_quick(file_path)
        for line, name, pattern in violations:
            all_violations.append((file_path, line, name, pattern))

    # Output results
    if all_violations:
        print(f"❌ Zero-Mock Violation: {len(all_violations)} mock patterns detected\n")
        for file_path, line, name, pattern in all_violations:
            rel_path = file_path.relative_to(project_root)
            print(f"  {rel_path}:{line} - {name} (contains '{pattern}')")
        print(f"\n💡 Tip: Replace mock implementations with real logic.")
        print(f"   See CONTRIBUTING.md for zero-mock policy details.")
        sys.exit(1)
    else:
        print("✅ Zero-Mock Check: No mock patterns detected")
        sys.exit(0)


if __name__ == "__main__":
    main()
```

#### **Script 2: Hardcoded Value Detection (detect_hardcoded_values.py)**

```python
#!/usr/bin/env python3
"""Detect functions that return only hardcoded constant values.

Zero-Mock Enforcement: Functions must perform real logic, not just
return hardcoded constants like `return 10` or `return True`.

Usage:
    python scripts/detect_hardcoded_values.py --fail-on-found
"""
import argparse
import ast
import sys
from pathlib import Path
from typing import List, Tuple, Any

EXCLUDE_PATTERNS = ["tests/", "test_", "_test.py", "conftest.py"]


def is_test_file(file_path: Path) -> bool:
    """Check if file is a test file (should be excluded)."""
    path_str = str(file_path)
    return any(pattern in path_str for pattern in EXCLUDE_PATTERNS)


def is_constant(node: ast.AST) -> bool:
    """Check if node is a constant value."""
    return isinstance(node, ast.Constant)


def is_error_only_function(func_node: ast.FunctionDef) -> bool:
    """Check if function only raises exceptions (no return value)."""
    for stmt in func_node.body:
        if isinstance(stmt, ast.Raise):
            continue
        elif isinstance(stmt, ast.Pass):
            continue
        elif isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant):
            # Docstring
            continue
        else:
            return False  # Has statements other than raise/pass/docstring
    return True


def detect_hardcoded_returns(file_path: Path) -> List[Tuple[int, str, Any]]:
    """Detect functions that return only constants.

    Returns: List of (line_number, function_name, constant_value) tuples
    """
    violations = []
    try:
        content = file_path.read_text()
        tree = ast.parse(content, filename=str(file_path))

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # Skip error-only functions
                if is_error_only_function(node):
                    continue

                # Check if function body contains only `return constant`
                returns = [stmt for stmt in ast.walk(node) if isinstance(stmt, ast.Return)]
                if returns and all(stmt.value and is_constant(stmt.value) for stmt in returns):
                    # All returns are constants - potential violation
                    const_value = returns[0].value.value if returns else None
                    violations.append((node.lineno, node.name, const_value))
    except Exception as e:
        print(f"Warning: Failed to parse {file_path}: {e}", file=sys.stderr)

    return violations


def main():
    parser = argparse.ArgumentParser(description="Detect hardcoded constant returns")
    parser.add_argument("--fail-on-found", action="store_true", help="Exit with code 1 if violations found")
    args = parser.parse_args()

    project_root = Path(__file__).parent.parent
    python_files = list(project_root.glob("rustybt/**/*.py"))
    python_files = [f for f in python_files if not is_test_file(f)]

    all_violations = []
    for file_path in python_files:
        violations = detect_hardcoded_returns(file_path)
        for line, name, const_value in violations:
            all_violations.append((file_path, line, name, const_value))

    if all_violations:
        print(f"❌ Zero-Mock Violation: {len(all_violations)} hardcoded return values detected\n")
        for file_path, line, name, const_value in all_violations:
            rel_path = file_path.relative_to(project_root)
            print(f"  {rel_path}:{line} - {name}() returns constant: {const_value}")
        print(f"\n💡 Tip: Replace hardcoded returns with real logic.")
        print(f"   If intentional, document with: # zero-mock: constant-return-justified")
        if args.fail_on_found:
            sys.exit(1)
    else:
        print("✅ Zero-Mock Check: No hardcoded constant returns detected")

    sys.exit(0)


if __name__ == "__main__":
    main()
```

#### **Script 3: Validation Function Testing (verify_validations.py)**

```python
#!/usr/bin/env python3
"""Verify validation functions actually reject invalid data.

Zero-Mock Enforcement: Validators must perform real checks, not just
return True or pass all inputs.

Usage:
    python scripts/verify_validations.py --ensure-real-checks
"""
import argparse
import ast
import sys
from pathlib import Path
from typing import List, Tuple

EXCLUDE_PATTERNS = ["tests/", "test_", "_test.py", "conftest.py"]
VALIDATOR_KEYWORDS = ["validate", "check", "verify", "assert"]


def is_test_file(file_path: Path) -> bool:
    """Check if file is a test file (should be excluded)."""
    path_str = str(file_path)
    return any(pattern in path_str for pattern in EXCLUDE_PATTERNS)


def is_validator_function(func_name: str) -> bool:
    """Check if function name suggests it's a validator."""
    name_lower = func_name.lower()
    return any(keyword in name_lower for keyword in VALIDATOR_KEYWORDS)


def is_always_pass_validator(func_node: ast.FunctionDef) -> bool:
    """Check if validator always passes (returns True or never raises)."""
    # Simple heuristic: check if function only contains `return True`
    for stmt in func_node.body:
        if isinstance(stmt, ast.Return) and isinstance(stmt.value, ast.Constant):
            if stmt.value.value is True:
                return True
    return False


def detect_always_pass_validators(file_path: Path) -> List[Tuple[int, str]]:
    """Detect validators that always pass.

    Returns: List of (line_number, function_name) tuples
    """
    violations = []
    try:
        content = file_path.read_text()
        tree = ast.parse(content, filename=str(file_path))

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if is_validator_function(node.name):
                    if is_always_pass_validator(node):
                        violations.append((node.lineno, node.name))
    except Exception as e:
        print(f"Warning: Failed to parse {file_path}: {e}", file=sys.stderr)

    return violations


def main():
    parser = argparse.ArgumentParser(description="Verify validation functions work correctly")
    parser.add_argument("--ensure-real-checks", action="store_true", help="Exit with code 1 if validators always pass")
    args = parser.parse_args()

    project_root = Path(__file__).parent.parent
    python_files = list(project_root.glob("rustybt/**/*.py"))
    python_files = [f for f in python_files if not is_test_file(f)]

    all_violations = []
    for file_path in python_files:
        violations = detect_always_pass_validators(file_path)
        for line, name in violations:
            all_violations.append((file_path, line, name))

    if all_violations:
        print(f"❌ Zero-Mock Violation: {len(all_violations)} always-pass validators detected\n")
        for file_path, line, name in all_violations:
            rel_path = file_path.relative_to(project_root)
            print(f"  {rel_path}:{line} - {name}() always returns True")
        print(f"\n💡 Tip: Validators must reject invalid data.")
        if args.ensure_real_checks:
            sys.exit(1)
    else:
        print("✅ Zero-Mock Check: No always-pass validators detected")

    sys.exit(0)


if __name__ == "__main__":
    main()
```

#### **Script 4: Result Uniqueness Testing (test_unique_results.py)**

```python
#!/usr/bin/env python3
"""Verify functions produce unique outputs for different inputs.

Zero-Mock Enforcement: Functions must perform real logic that produces
different outputs for different inputs (not just return same value always).

Usage:
    python scripts/test_unique_results.py --sample-size 10
"""
import argparse
import sys
from pathlib import Path

# Note: This is a simplified placeholder
# Full implementation would require function signature analysis,
# input generation, and execution - which is complex for static analysis

def main():
    parser = argparse.ArgumentParser(description="Test function result uniqueness")
    parser.add_argument("--sample-size", type=int, default=10, help="Number of test calls per function")
    args = parser.parse_args()

    print("ℹ️  Result uniqueness testing is placeholder (requires runtime analysis)")
    print("✅ Zero-Mock Check: Skipping result uniqueness (not implemented yet)")
    sys.exit(0)


if __name__ == "__main__":
    main()
```

#### **Pre-Commit Hook Configuration:**

```yaml
# Add to .pre-commit-config.yaml
  - repo: local
    hooks:
      - id: detect-mocks
        name: Detect Mock Patterns (Zero-Mock Enforcement)
        entry: python scripts/detect_mocks.py --quick
        language: system
        types: [python]
        exclude: ^tests/
```

#### **CI Workflow (Prepared for X2.2C):**

```yaml
# .github/workflows/zero-mock-enforcement.yml
# DO NOT ACTIVATE UNTIL X2.2C STORY - this workflow is prepared but not enabled yet
name: Zero-Mock Enforcement

on:
  push:
    branches: [main, develop]
  pull_request:

jobs:
  mock-detection:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3

      - name: Detect mock patterns (BLOCKING)
        run: |
          python scripts/detect_mocks.py --strict
          if [ $? -ne 0 ]; then
            echo "::error::Mock patterns detected! Real implementations required."
            exit 1
          fi

      - name: Detect hardcoded values (BLOCKING)
        run: |
          python scripts/detect_hardcoded_values.py --fail-on-found

      - name: Verify validations work (BLOCKING)
        run: |
          python scripts/verify_validations.py --ensure-real-checks

      - name: Test result uniqueness (BLOCKING)
        run: |
          python scripts/test_unique_results.py

# ACTIVATION INSTRUCTIONS FOR X2.2C:
# 1. Uncomment workflow file name
# 2. Configure branch protection rules to require this check
# 3. Test with sample PR
```

### Testing

**Test File Locations:**
- Unit tests: `tests/scripts/test_detect_mocks.py`

**Test Standards:**
- Test positive cases (violations detected)
- Test negative cases (clean code passes)
- Test file exclusions (test files ignored)
- Test CLI flags and exit codes
- Test error handling (unparseable files)

**Testing Frameworks:**
- pytest for unit tests

**CI Test Commands:**
```bash
# Run zero-mock detection scripts
python scripts/detect_mocks.py --strict
python scripts/detect_hardcoded_values.py --fail-on-found
python scripts/verify_validations.py --ensure-real-checks
python scripts/test_unique_results.py

# Run unit tests
pytest tests/scripts/test_detect_mocks.py
```

## Change Log

| Date       | Version | Description                                   | Author    |
|------------|---------|-----------------------------------------------|-----------|
| 2025-10-11 | 1.0     | Split from X2.2 per Epic X2 structure         | PO (Sarah)|

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be filled by dev agent*

### Debug Log References

*To be filled by dev agent*

### Completion Notes List

*To be filled by dev agent*

### File List

*To be filled by dev agent*

## QA Results

*This section will be populated by the QA agent after story completion.*
