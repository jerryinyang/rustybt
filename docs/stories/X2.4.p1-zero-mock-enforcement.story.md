# Story X2.4: P1 Zero-Mock Enforcement

## Status
Draft

## Story

**As a** Software Engineer enforcing code quality standards,
**I want** mandatory zero-mock detection and enforcement with automated scripts and pre-commit hooks,
**so that** production code contains only real implementations and passes rigorous validation checks.

## Acceptance Criteria

### Mock Detection Scripts

1. **Mock Detection Scripts Created**
   - Create `scripts/detect_mocks.py` → Scan for mock patterns (function names with "mock"/"fake"/"stub", hardcoded return values)
   - Create `scripts/detect_hardcoded_values.py` → Detect functions that return constants (return 10, return True, return 1.5)
   - Create `scripts/verify_validations.py` → Verify validation functions actually reject invalid data
   - Create `scripts/test_unique_results.py` → Verify different inputs produce different outputs
   - Add pre-commit hook for `detect_mocks.py --quick`

2. **Zero-Mock Enforcement Validation**
   - Run `pre-commit run --all-files` → 0 mock violations found
   - Run `python scripts/detect_mocks.py --strict` → 0 mock patterns detected
   - Run `python scripts/detect_hardcoded_values.py --fail-on-found` → 0 hardcoded values found
   - Run `python scripts/verify_validations.py --ensure-real-checks` → All validators functional
   - Run `python scripts/test_unique_results.py` → All functions produce unique outputs
   - Document zero-mock policy in CONTRIBUTING.md with examples of forbidden patterns

### Integration Requirements

3. **Pre-Commit Integration**
   - Zero-mock detection hook added to `.pre-commit-config.yaml`
   - Hook runs fast (< 2 seconds for typical commit)
   - Hook provides clear error messages with line numbers
   - Hook can be bypassed in emergencies (but discouraged)

4. **CI Workflow Prepared**
   - Zero-mock enforcement workflow YAML prepared (activated in Story X2.5)
   - Workflow includes all 4 detection scripts as BLOCKING jobs
   - Workflow configured to run on push and pull_request

### Quality Requirements

5. **Policy Documentation**
   - CONTRIBUTING.md documents zero-mock policy with forbidden pattern examples
   - Examples provided for allowed vs. forbidden patterns
   - Rationale explained: real implementations required for production reliability
   - Guidance provided for writing tests without mocks

6. **No Regression Verified**
   - All existing tests pass
   - No false positives from detection scripts
   - Scripts run efficiently (< 30 seconds total for full codebase scan)

## Tasks / Subtasks

- [ ] **Task 1: Create Mock Detection Scripts** (AC: 1)
  - [ ] Create `scripts/detect_mocks.py` with mock pattern detection
  - [ ] Create `scripts/detect_hardcoded_values.py` with constant return detection
  - [ ] Create `scripts/verify_validations.py` with validator testing
  - [ ] Create `scripts/test_unique_results.py` with output uniqueness testing
  - [ ] Test all scripts locally

- [ ] **Task 2: Run Zero-Mock Validation** (AC: 2)
  - [ ] Run all zero-mock detection scripts → verify 0 violations
  - [ ] Document any findings and remediate if needed

- [ ] **Task 3: Configure Pre-Commit Hook** (AC: 3)
  - [ ] Add `detect_mocks.py --quick` to `.pre-commit-config.yaml`
  - [ ] Test hook with sample commit
  - [ ] Verify hook performance (< 2s)

- [ ] **Task 4: Prepare CI Workflow** (AC: 4)
  - [ ] Create `.github/workflows/zero-mock-enforcement.yml` (not activated yet)
  - [ ] Add all detection scripts as BLOCKING jobs
  - [ ] Document activation in Story X2.5

- [ ] **Task 5: Document Policy** (AC: 5)
  - [ ] Update CONTRIBUTING.md with zero-mock policy
  - [ ] Add examples of forbidden patterns
  - [ ] Add examples of allowed patterns
  - [ ] Add guidance for writing tests without mocks

- [ ] **Task 6: Final Validation** (AC: 6)
  - [ ] Run full test suite → all pass
  - [ ] Verify no false positives
  - [ ] Verify scripts run efficiently

## Dev Notes

### Architecture Context

**Source:** [docs/architecture/coding-standards.md](../architecture/coding-standards.md)

**Zero-Mock Policy:**
- No mocking of production code (unit tests use real implementations)
- Test coverage: ≥90% overall, ≥95% financial modules
- Validation functions must actually reject invalid data

**Relevant Source Locations:**
- Scripts: `scripts/` (detect_mocks.py, detect_hardcoded_values.py, verify_validations.py, test_unique_results.py)
- Pre-commit config: `.pre-commit-config.yaml`
- CI workflows: `.github/workflows/zero-mock-enforcement.yml`
- Documentation: `CONTRIBUTING.md`

### Technical Implementation Guidance

**Pre-Commit Hook Configuration:**
```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: detect-mocks
        name: Detect Mock Patterns
        entry: python scripts/detect_mocks.py --quick
        language: system
        types: [python]
```

**Zero-Mock Policy Examples:**
```python
# FORBIDDEN: Mock implementation
def validate_price(price):
    return True  # Always returns True - FORBIDDEN

# ALLOWED: Real implementation
def validate_price(price):
    if not isinstance(price, Decimal):
        raise TypeError("Price must be Decimal")
    if price <= Decimal("0"):
        raise ValueError("Price must be positive")
    return True
```

**Mock Detection Script (detect_mocks.py):**

**Purpose:** Scan Python files for mock patterns in function/variable names and identify suspicious implementations.

**Detection Patterns:**
1. Function/variable names containing: `mock`, `fake`, `stub`, `dummy`, `placeholder`
2. Class names inheriting from Mock-like classes
3. Import statements with mock libraries in production code

**Algorithm:**
```python
# scripts/detect_mocks.py
import ast
import sys
from pathlib import Path
from typing import List, Tuple

class MockDetector(ast.NodeVisitor):
    def __init__(self):
        self.violations: List[Tuple[int, str]] = []
        self.mock_keywords = ['mock', 'fake', 'stub', 'dummy', 'placeholder']

    def visit_FunctionDef(self, node: ast.FunctionDef):
        # Check function name
        if any(keyword in node.name.lower() for keyword in self.mock_keywords):
            self.violations.append((node.lineno, f"Mock function name: {node.name}"))
        self.generic_visit(node)

    def visit_ClassDef(self, node: ast.ClassDef):
        # Check class name
        if any(keyword in node.name.lower() for keyword in self.mock_keywords):
            self.violations.append((node.lineno, f"Mock class name: {node.name}"))
        self.generic_visit(node)

    def visit_Import(self, node: ast.Import):
        # Check for mock imports in production code
        for alias in node.names:
            if 'mock' in alias.name.lower() or 'unittest.mock' in alias.name:
                self.violations.append((node.lineno, f"Mock import: {alias.name}"))
        self.generic_visit(node)

def scan_file(filepath: Path) -> List[Tuple[int, str]]:
    """Scan a single Python file for mock patterns."""
    with open(filepath, 'r', encoding='utf-8') as f:
        try:
            tree = ast.parse(f.read(), filename=str(filepath))
        except SyntaxError:
            return []

    detector = MockDetector()
    detector.visit(tree)
    return detector.violations

def main():
    # Scan all Python files in rustybt/
    rustybt_dir = Path('rustybt')
    violations_found = False

    for py_file in rustybt_dir.rglob('*.py'):
        violations = scan_file(py_file)
        if violations:
            violations_found = True
            print(f"\n{py_file}:")
            for lineno, msg in violations:
                print(f"  Line {lineno}: {msg}")

    if violations_found:
        sys.exit(1)
    else:
        print("✅ No mock patterns detected")
        sys.exit(0)

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
# Quick check (pre-commit)
python scripts/detect_mocks.py --quick

# Strict check (CI)
python scripts/detect_mocks.py --strict
```

---

**Hardcoded Values Detection Script (detect_hardcoded_values.py):**

**Purpose:** Identify functions that return constant values (hardcoded returns).

**Detection Patterns:**
1. Functions with single `return <constant>` statement
2. Constants: integers, floats, strings, True/False
3. Exclude: None, empty collections, constants from class attributes

**Algorithm:**
```python
# scripts/detect_hardcoded_values.py
import ast
import sys
from pathlib import Path
from typing import List, Tuple

class HardcodedReturnDetector(ast.NodeVisitor):
    def __init__(self):
        self.violations: List[Tuple[int, str, str]] = []

    def visit_FunctionDef(self, node: ast.FunctionDef):
        # Check if function body is single return statement
        if len(node.body) == 1 and isinstance(node.body[0], ast.Return):
            ret_node = node.body[0]
            if ret_node.value and self._is_constant(ret_node.value):
                value_str = ast.unparse(ret_node.value)
                self.violations.append((
                    node.lineno,
                    node.name,
                    value_str
                ))

        # Also check for functions with only docstring + return constant
        if len(node.body) == 2:
            if isinstance(node.body[0], ast.Expr) and isinstance(node.body[0].value, ast.Constant):
                if isinstance(node.body[1], ast.Return):
                    ret_node = node.body[1]
                    if ret_node.value and self._is_constant(ret_node.value):
                        value_str = ast.unparse(ret_node.value)
                        self.violations.append((
                            node.lineno,
                            node.name,
                            value_str
                        ))

        self.generic_visit(node)

    def _is_constant(self, node: ast.AST) -> bool:
        """Check if node is a constant value."""
        if isinstance(node, ast.Constant):
            # Exclude None (acceptable return)
            if node.value is None:
                return False
            # Detect hardcoded numbers, strings, booleans
            if isinstance(node.value, (int, float, str, bool)):
                return True
        return False

def scan_file(filepath: Path) -> List[Tuple[int, str, str]]:
    """Scan a single Python file for hardcoded return values."""
    with open(filepath, 'r', encoding='utf-8') as f:
        try:
            tree = ast.parse(f.read(), filename=str(filepath))
        except SyntaxError:
            return []

    detector = HardcodedReturnDetector()
    detector.visit(tree)
    return detector.violations

def main():
    rustybt_dir = Path('rustybt')
    violations_found = False

    for py_file in rustybt_dir.rglob('*.py'):
        # Skip test files and __init__.py
        if 'test' in py_file.name or py_file.name == '__init__.py':
            continue

        violations = scan_file(py_file)
        if violations:
            violations_found = True
            print(f"\n{py_file}:")
            for lineno, func_name, value in violations:
                print(f"  Line {lineno}: Function '{func_name}' returns hardcoded value: {value}")

    if violations_found:
        print("\n❌ Hardcoded return values detected")
        sys.exit(1)
    else:
        print("✅ No hardcoded return values detected")
        sys.exit(0)

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
# Check for hardcoded values (fail on found)
python scripts/detect_hardcoded_values.py --fail-on-found
```

---

**Validation Verification Script (verify_validations.py):**

**Purpose:** Verify that validation functions actually reject invalid data.

**Detection Strategy:**
1. Find all functions with "validate" in name
2. Test with intentionally invalid inputs
3. Verify they raise exceptions or return False

**Algorithm:**
```python
# scripts/verify_validations.py
import importlib
import inspect
import sys
from pathlib import Path
from typing import List, Callable

def find_validation_functions() -> List[Callable]:
    """Find all validation functions in rustybt package."""
    validators = []

    # Import rustybt package
    import rustybt

    # Recursively find modules
    for module_path in Path('rustybt').rglob('*.py'):
        if 'test' in str(module_path) or module_path.name == '__init__.py':
            continue

        # Convert path to module name
        module_name = str(module_path).replace('/', '.').replace('.py', '')

        try:
            module = importlib.import_module(module_name)
        except:
            continue

        # Find functions with 'validate' in name
        for name, obj in inspect.getmembers(module, inspect.isfunction):
            if 'validate' in name.lower():
                validators.append((module_name, name, obj))

    return validators

def test_validator(module_name: str, func_name: str, func: Callable) -> bool:
    """Test if validator rejects invalid data."""
    # Get function signature
    sig = inspect.signature(func)

    # Prepare invalid test inputs
    invalid_inputs = {
        'str': ['', None, 123, [], {}],
        'int': [None, 'invalid', [], {}],
        'float': [None, 'invalid', [], {}],
        'Decimal': [None, 'invalid', 0.1, []],
        'dict': [None, 'invalid', [], 123],
        'list': [None, 'invalid', {}, 123],
    }

    # Try to call with invalid inputs
    try:
        # Simple test: call with None if single parameter
        if len(sig.parameters) == 1:
            try:
                result = func(None)
                # If it returns True or doesn't raise, it's a bad validator
                if result is True:
                    return False
            except:
                # Good - it raised an exception for invalid input
                return True

        return True  # Can't test multi-param validators easily
    except:
        return True

def main():
    validators = find_validation_functions()
    print(f"Found {len(validators)} validation functions")

    bad_validators = []
    for module_name, func_name, func in validators:
        if not test_validator(module_name, func_name, func):
            bad_validators.append(f"{module_name}.{func_name}")

    if bad_validators:
        print("\n❌ Validators that always return True:")
        for validator in bad_validators:
            print(f"  - {validator}")
        sys.exit(1)
    else:
        print("✅ All validators reject invalid data")
        sys.exit(0)

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
# Verify validation functions work
python scripts/verify_validations.py --ensure-real-checks
```

---

**Unique Results Test Script (test_unique_results.py):**

**Purpose:** Verify that functions produce different outputs for different inputs.

**Detection Strategy:**
1. Find functions that take parameters
2. Call with different inputs
3. Verify outputs are different

**Algorithm:**
```python
# scripts/test_unique_results.py
import importlib
import inspect
import sys
from pathlib import Path
from typing import List, Callable, Any
from decimal import Decimal

def find_testable_functions() -> List[Callable]:
    """Find functions that can be tested for unique results."""
    functions = []

    for module_path in Path('rustybt').rglob('*.py'):
        if 'test' in str(module_path) or module_path.name == '__init__.py':
            continue

        module_name = str(module_path).replace('/', '.').replace('.py', '')

        try:
            module = importlib.import_module(module_name)
        except:
            continue

        for name, obj in inspect.getmembers(module, inspect.isfunction):
            # Only test pure calculation functions
            if any(keyword in name.lower() for keyword in ['calculate', 'compute', 'process']):
                sig = inspect.signature(obj)
                # Only test if function takes parameters
                if len(sig.parameters) > 0:
                    functions.append((module_name, name, obj))

    return functions

def test_function_uniqueness(module_name: str, func_name: str, func: Callable) -> bool:
    """Test if function produces unique results for different inputs."""
    sig = inspect.signature(func)

    # Generate test inputs
    test_inputs = [
        (Decimal('10'),),
        (Decimal('20'),),
        (Decimal('30'),),
    ]

    try:
        results = set()
        for inputs in test_inputs:
            result = func(*inputs)
            if result is not None:
                # Convert to hashable type
                if isinstance(result, (int, float, str, Decimal)):
                    results.add(result)

        # If all results are the same, it's suspicious
        if len(results) == 1 and len(test_inputs) > 1:
            return False

        return True
    except:
        # Can't test - skip
        return True

def main():
    functions = find_testable_functions()
    print(f"Testing {len(functions)} functions for unique results")

    suspicious_functions = []
    for module_name, func_name, func in functions:
        if not test_function_uniqueness(module_name, func_name, func):
            suspicious_functions.append(f"{module_name}.{func_name}")

    if suspicious_functions:
        print("\n⚠️ Functions that produce identical results for different inputs:")
        for func_name in suspicious_functions:
            print(f"  - {func_name}")
        sys.exit(1)
    else:
        print("✅ All functions produce unique results")
        sys.exit(0)

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
# Test result uniqueness
python scripts/test_unique_results.py
```

---

**Zero-Mock Policy Documentation:**

**Forbidden Patterns:**
```python
# ❌ FORBIDDEN: Hardcoded return values
def calculate_sharpe_ratio(returns):
    return 1.5  # Mock value - FORBIDDEN

def validate_price(price):
    return True  # Always passes - FORBIDDEN

# ❌ FORBIDDEN: Mock implementations
def mock_get_price(asset):
    return Decimal("100")

class FakeBroker:
    def submit_order(self, order):
        return "fake-order-123"

# ❌ FORBIDDEN: Placeholder implementations
def calculate_returns(data):
    pass  # TODO: implement later - FORBIDDEN
```

**Allowed Patterns:**
```python
# ✅ ALLOWED: Real calculation
def calculate_sharpe_ratio(returns: pl.Series) -> Decimal:
    """Calculate actual Sharpe ratio from returns series."""
    if len(returns) < 2:
        raise ValueError("Insufficient data")
    mean_return = returns.mean()
    std_return = returns.std()
    if std_return == 0:
        return Decimal(0)
    return Decimal(str(mean_return / std_return))

# ✅ ALLOWED: Real validation
def validate_price(price: Decimal) -> bool:
    """Validate price is positive Decimal."""
    if not isinstance(price, Decimal):
        raise TypeError("Price must be Decimal")
    if price <= Decimal("0"):
        raise ValueError("Price must be positive")
    return True

# ✅ ALLOWED: Real implementation
def get_price(self, asset: Asset, dt: pd.Timestamp) -> Decimal:
    """Get actual price from data portal."""
    return self._data_portal.get_price(asset, dt)

# ✅ ALLOWED: Test fixtures (in test files only)
@pytest.fixture
def sample_broker():
    """Create real broker instance for testing."""
    return PaperBroker(initial_capital=Decimal("100000"))
```

**Integration with CI/CD:**
- Pre-commit hook runs `detect_mocks.py --quick` (< 2 seconds)
- CI runs all 4 detection scripts (BLOCKING)
- CI workflow prepared in X2.4, activated in X2.5

### Testing

**Source:** [docs/architecture/testing-strategy.md](../architecture/testing-strategy.md)

**Test Standards:**
- Detection scripts themselves should be tested
- Test with known mock patterns to verify detection works
- Test with clean code to verify no false positives

**Testing Commands:**

```bash
# Test detection scripts work
# Create test file with mock patterns
cat > /tmp/test_mock.py <<'EOF'
def mock_calculate():
    return 10

def validate_data(data):
    return True
EOF

# Run detection (should find violations)
python scripts/detect_mocks.py --file /tmp/test_mock.py
python scripts/detect_hardcoded_values.py --file /tmp/test_mock.py

# Test on clean code (should pass)
python scripts/detect_mocks.py --file rustybt/exceptions.py
python scripts/detect_hardcoded_values.py --file rustybt/exceptions.py

# Full codebase scan
python scripts/detect_mocks.py --strict
python scripts/detect_hardcoded_values.py --fail-on-found
python scripts/verify_validations.py --ensure-real-checks
python scripts/test_unique_results.py
```

**Pre-Commit Hook Testing:**

```bash
# Install pre-commit hooks
pre-commit install

# Run all hooks manually
pre-commit run --all-files

# Test with sample commit containing mock code (should block)
echo "def mock_func(): return 10" > test.py
git add test.py
git commit -m "test" # Should be blocked by detect_mocks hook
git reset HEAD test.py
rm test.py
```

## Change Log

| Date       | Version | Description                          | Author    |
|------------|---------|--------------------------------------|-----------|
| 2025-10-11 | 1.0     | Initial story creation, renumbered   | SM (Bob)  |

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be filled by dev agent*

### Debug Log References

*To be filled by dev agent*

### Completion Notes List

*To be filled by dev agent*

### File List

*To be filled by dev agent*

## QA Results

*This section will be populated by the QA agent after story completion.*
